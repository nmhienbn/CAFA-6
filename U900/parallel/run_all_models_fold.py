import os
import subprocess
import multiprocessing
import time
import sys
import yaml
import numpy as np
import joblib

# --- C·∫§U H√åNH ---
BASE_PATH = "./"
CONFIG_PATH = "config.yaml"
LOG_DIR = "logs"

# Python Environments
RAPIDS_ENV = "rapids-env/bin/python" 
PYTORCH_ENV = "pytorch-env/bin/python"

# --- KHAI B√ÅO MODEL ---
# C·∫•u tr√∫c: (Environment, Script Path, Model Name)
# L∆∞u √Ω: Script ph·∫£i l√† c√°c file "_fold.py" ƒë√£ s·ª≠a ƒë·ªïi ƒë·ªÉ ch·∫°y t·ª´ng fold
models_to_run = [
    # # --- NH√ìM 1: PY-BOOST (4 Models) ---
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_pb_fold.py", "pb_t54500_raw"),
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_pb_fold.py", "pb_t54500_cond"),
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_pb_fold.py", "pb_t5esm4500_raw"),
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_pb_fold.py", "pb_t5esm4500_cond"),
    
    # # --- NH√ìM 2: LINEAR (2 Models) ---
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_lin_fold.py", "lin_t5_raw"),
    # (RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/train_lin_fold.py", "lin_t5_cond"),

    # --- NH√ìM 3: NEURAL NETWORK (1 Model) ---
    # Thay th·∫ø to√†n b·ªô pipeline tu·∫ßn t·ª± c≈© b·∫±ng 1 script ch·∫°y fold song song
    (PYTORCH_ENV, f"{BASE_PATH}/nn_solution/train_nn_fold.py", "nn_pMLP"),
]

FOLDS = [0, 1, 2, 3, 4]
NUM_GPUS = 8  # B·∫°n c√≥ 8x A100

def worker(gpu_id, task_queue):
    """Worker ch·∫°y tr√™n GPU ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
    print(f"üöÄ [GPU {gpu_id}] Worker online.")
    
    while True:
        try:
            if task_queue.empty(): break
            
            # L·∫•y nhi·ªám v·ª•
            env, script, model_name, fold = task_queue.get_nowait()
            
            # T·∫°o file log ri√™ng
            log_path = os.path.join(LOG_DIR, f"{model_name}_fold{fold}.log")
            
            # C√¢u l·ªánh ch·∫°y
            cmd = [
                env, script,
                "--config-path", CONFIG_PATH,
                "--model-name", model_name,
                "--device", str(gpu_id),
                "--fold", str(fold)
            ]
            
            print(f"    ‚ñ∂ [GPU {gpu_id}] Running: {model_name} | Fold {fold}")
            
            with open(log_path, "w") as f_log:
                try:
                    subprocess.run(cmd, stdout=f_log, stderr=subprocess.STDOUT, check=True)
                except subprocess.CalledProcessError:
                    f_log.write(f"\n[ERROR] Process failed for Fold {fold}\n")
                    print(f"    ‚ùå [GPU {gpu_id}] FAILED: {model_name} | Fold {fold} (Check logs)")
        
        except Exception:
            break
            
    print(f"‚úÖ [GPU {gpu_id}] Completed all assigned tasks.")

def merge_outputs():
    """T·ª± ƒë·ªông g·ªôp k·∫øt qu·∫£ cho T·∫§T C·∫¢ c√°c model trong danh s√°ch"""
    print("\nüîÑ ƒêANG G·ªòP K·∫æT QU·∫¢ (MERGING)...")
    
    with open(CONFIG_PATH) as f:
        config = yaml.safe_load(f)
    models_root = os.path.join(config['base_path'], config['models_path'])

    # L·∫•y danh s√°ch t√™n model duy nh·∫•t
    unique_models = sorted(list(set([m[2] for m in models_to_run])))

    for model_name in unique_models:
        model_dir = os.path.join(models_root, model_name)
        if not os.path.exists(model_dir):
            print(f"‚ö†Ô∏è  B·ªè qua {model_name} (Ch∆∞a th·∫•y th∆∞ m·ª•c output)")
            continue

        print(f"   -> Processing: {model_name}...", end=" ")
        
        try:
            # --- TR∆Ø·ªúNG H·ª¢P 1: NEURAL NETWORK (File .npy) ---
            if "nn_" in model_name:
                # Merge OOF
                oof_files = [os.path.join(model_dir, f'temp_oof_fold_{f}.npy') for f in FOLDS]
                if all(os.path.exists(f) for f in oof_files):
                    # C·ªông d·ªìn c√°c fold l·∫°i (v√¨ m·ªói file ch·ªâ ch·ª©a gi√° tr·ªã t·∫°i v·ªã tr√≠ val)
                    full_oof = sum(np.load(f) for f in oof_files)
                    np.save(os.path.join(model_dir, 'Y_pred_oof_blend.npy'), full_oof)
                
                # Merge Test (Submission)
                test_files = [os.path.join(model_dir, f'temp_test_fold_{f}.npy') for f in FOLDS]
                if all(os.path.exists(f) for f in test_files):
                    # Test th√¨ l·∫•y trung b√¨nh c·ªông
                    full_test = sum(np.load(f) for f in test_files) / len(FOLDS)
                    np.save(os.path.join(model_dir, 'Y_submit.npy'), full_test)
                print("OK (Format .npy)")

            # --- TR∆Ø·ªúNG H·ª¢P 2: PY-BOOST & LINEAR (File .pkl) ---
            else:
                # Merge OOF
                oof_files = [os.path.join(model_dir, f'temp_oof_fold_{f}.pkl') for f in FOLDS]
                if all(os.path.exists(f) for f in oof_files):
                    full_oof = sum(joblib.load(f) for f in oof_files)
                    joblib.dump(full_oof, os.path.join(model_dir, 'oof_pred.pkl'))
                
                # Merge Test
                test_files = [os.path.join(model_dir, f'temp_test_fold_{f}.pkl') for f in FOLDS]
                if all(os.path.exists(f) for f in test_files):
                    full_test = sum(joblib.load(f) for f in test_files) / len(FOLDS)
                    joblib.dump(full_test, os.path.join(model_dir, 'test_pred.pkl'))
                print("OK (Format .pkl)")

        except Exception as e:
            print(f"\n      ‚ùå L·ªói khi g·ªôp {model_name}: {e}")

    print("\n‚ú® T·∫§T C·∫¢ ƒê√É HO√ÄN T·∫§T!")

def main():
    os.makedirs(LOG_DIR, exist_ok=True)
    task_queue = multiprocessing.Queue()
    
    # 1. ƒê·∫©y 35 tasks v√†o h√†ng ƒë·ª£i (7 models * 5 folds)
    for env, script, model_name in models_to_run:
        for fold in FOLDS:
            task_queue.put((env, script, model_name, fold))
            
    print(f"--- B·∫Øt ƒë·∫ßu Train Ph√¢n T√°n tr√™n {NUM_GPUS} GPU A100 ---")
    print(f"--- T·ªïng t√°c v·ª•: {len(models_to_run) * len(FOLDS)} ---")
    
    # 2. Kh·ªüi ch·∫°y 8 Workers
    processes = []
    for gpu_id in range(NUM_GPUS):
        p = multiprocessing.Process(target=worker, args=(gpu_id, task_queue))
        processes.append(p)
        p.start()
        time.sleep(1) 
        
    # 3. Ch·ªù xong
    for p in processes:
        p.join()

    # 4. G·ªôp k·∫øt qu·∫£
    merge_outputs()

if __name__ == "__main__":
    main()