import os
import subprocess
import multiprocessing
import time
import sys
import joblib
import numpy as np
import yaml

# --- C·∫§U H√åNH ---
BASE_PATH = "./"
CONFIG_PATH = "config.yaml"
LOG_DIR = "logs"
MODEL_NAME = "lin_t5_cond"  # <-- ƒê·ªîI T√äN MODEL C·∫¶N CH·∫†Y ·ªû ƒê√ÇY

# Python paths
RAPIDS_ENV = "rapids-env/bin/python" 
PYTORCH_ENV = "pytorch-env/bin/python"

# Script paths
TRAIN_WORKER_SCRIPT = f"{BASE_PATH}/protlib/scripts/train_lin_fold.py" # File worker m√¨nh v·ª´a vi·∫øt ·ªü tr√™n

# --- KHAI B√ÅO T√ÅC V·ª§ (T·ª± ƒë·ªông sinh cho 5 GPU) ---
# Format: (GPU_ID, [(ENV, SCRIPT, MODEL_NAME, FOLD_ID)])
tasks = []
for fold in range(5):
    # Map fold 0 -> GPU 0, fold 1 -> GPU 1, ..., fold 4 -> GPU 4
    gpu_id = str(fold)
    tasks.append((gpu_id, [(RAPIDS_ENV, TRAIN_WORKER_SCRIPT, MODEL_NAME, fold)]))


def run_worker(gpu_id, command_list):
    """Ch·∫°y list l·ªánh tr√™n GPU ch·ªâ ƒë·ªãnh v√† ghi log ra file."""
    
    print(f"üöÄ [GPU {gpu_id}] Worker started.")

    for py_env, script, model_name, fold_id in command_list:
        # X√¢y d·ª±ng t√™n file log: tenmodel_foldX.log
        log_filename = f"{model_name}_fold{fold_id}.log"
        log_path = os.path.join(LOG_DIR, log_filename)
        
        # T·∫°o c√¢u l·ªánh
        cmd = [
            py_env, script, 
            "--config-path", CONFIG_PATH,
            "--model-name", model_name,
            "--device", str(gpu_id),
            "--fold", str(fold_id)
        ]

        print(f"    ‚ñ∂ [GPU {gpu_id}] ƒêang ch·∫°y Fold {fold_id} cho model: {model_name}")
        print(f"      üìÑ Logs -> {log_path}")
        
        # M·ªü file log ƒë·ªÉ ghi
        with open(log_path, "w") as f_log:
            try:
                # Set unbuffered ƒë·ªÉ log hi·ªán ngay
                env = os.environ.copy()
                env["PYTHONUNBUFFERED"] = "1"
                
                subprocess.run(cmd, stdout=f_log, stderr=subprocess.STDOUT, check=True, env=env)
            except subprocess.CalledProcessError:
                f_log.write(f"\n\n[ERROR] Process failed with exit code 1.\n")
                print(f"    ‚ùå [GPU {gpu_id}] L·ªói Fold {fold_id}! Ki·ªÉm tra file {log_path}.")
                return 

    print(f"‚úÖ [GPU {gpu_id}] Ho√†n th√†nh Fold {fold_id}!")


def merge_results(model_name):
    """G·ªôp k·∫øt qu·∫£ t·ª´ 5 fold l·∫°i th√†nh file cu·ªëi c√πng."""
    print(f"\nüîÑ ƒêang g·ªôp k·∫øt qu·∫£ cho {model_name}...")
    
    with open(CONFIG_PATH) as f:
        config = yaml.safe_load(f)
    
    output_dir = os.path.join(config['base_path'], config['models_path'], model_name)
    
    try:
        # Merge OOF & Test
        # Load file m·∫´u ƒë·ªÉ l·∫•y shape
        first_oof = joblib.load(os.path.join(output_dir, 'temp_oof_fold_0.pkl'))
        final_oof = np.zeros_like(first_oof)
        
        first_test = joblib.load(os.path.join(output_dir, 'temp_test_fold_0.pkl'))
        final_test = np.zeros_like(first_test)

        for f in range(5):
            oof_path = os.path.join(output_dir, f'temp_oof_fold_{f}.pkl')
            test_path = os.path.join(output_dir, f'temp_test_fold_{f}.pkl')
            
            final_oof += joblib.load(oof_path)
            final_test += joblib.load(test_path)
            
            # X√≥a file t·∫°m (Clean up)
            if os.path.exists(oof_path): os.remove(oof_path)
            if os.path.exists(test_path): os.remove(test_path)

        final_test /= 5.0 # Chia trung b√¨nh cho test set

        joblib.dump(final_oof, os.path.join(output_dir, 'oof_pred.pkl'))
        joblib.dump(final_test, os.path.join(output_dir, 'test_pred.pkl'))
        
        print(f"üéâ G·ªôp xong! File l∆∞u t·∫°i: {output_dir}")

    except Exception as e:
        print(f"‚ùå L·ªói khi g·ªôp k·∫øt qu·∫£: {e}")
        print("H√£y ki·ªÉm tra xem t·∫•t c·∫£ c√°c fold worker ƒë√£ ch·∫°y xong ch∆∞a.")


def main():
    # 1. T·∫°o th∆∞ m·ª•c logs
    os.makedirs(LOG_DIR, exist_ok=True)
    
    # L∆∞u √Ω: Code c≈© c·ªßa b·∫°n c√≥ b∆∞·ªõc "T·∫°o K-Folds" (create_gkf.py).
    # Trong logic m·ªõi n√†y, vi·ªác chia fold ƒë∆∞·ª£c x·ª≠ l√Ω deterministically b·∫±ng seed trong train_worker.py 
    # n√™n kh√¥ng nh·∫•t thi·∫øt ph·∫£i ch·∫°y create_gkf.py tr∆∞·ªõc, TR·ª™ KHI script create_gkf.py l√†m vi·ªác kh√°c quan tr·ªçng.
    # N·∫øu c·∫ßn th√¨ uncomment d√≤ng d∆∞·ªõi:
    # print("--- B∆∞·ªõc 0: T·∫°o K-Folds (Optional) ---")
    # subprocess.run([RAPIDS_ENV, f"{BASE_PATH}/protlib/scripts/create_gkf.py", "--config-path", CONFIG_PATH])

    print(f"üöÄ B·∫Øt ƒë·∫ßu train song song model: {MODEL_NAME} tr√™n 5 GPU...\n")

    # 2. Kh·ªüi ƒë·ªông c√°c Workers
    processes = []
    for gpu_id, cmds in tasks:
        p = multiprocessing.Process(target=run_worker, args=(gpu_id, cmds))
        processes.append(p)
        p.start()
        time.sleep(1) # Delay nh·ªè ƒë·ªÉ tr√°nh spam log c√πng l√∫c

    # 3. Ch·ªù ho√†n th√†nh
    failed = False
    for p in processes:
        p.join()
        if p.exitcode != 0:
            failed = True

    if not failed:
        # 4. G·ªôp k·∫øt qu·∫£ n·∫øu ch·∫°y th√†nh c√¥ng
        merge_results(MODEL_NAME)
        print("\nüéâ T·∫§T C·∫¢ ƒê√É XONG! Ki·ªÉm tra th∆∞ m·ª•c 'logs/' ƒë·ªÉ xem chi ti·∫øt.")
    else:
        print("\n‚ùå C√≥ l·ªói x·∫£y ra ·ªü m·ªôt s·ªë GPU. Kh√¥ng g·ªôp k·∫øt qu·∫£.")

if __name__ == "__main__":
    main()