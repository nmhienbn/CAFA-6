import os
import subprocess
import multiprocessing
import time
import yaml

# --- C·∫§U H√åNH ---
BASE_PATH = "./"
CONFIG_PATH = "config.yaml"
LOG_DIR = "logs_gcn"
WORKER_SCRIPT = "protnn/scripts/predict_gcn.py" # T√™n file worker b·∫°n v·ª´a l∆∞u ·ªü tr√™n

# Python path (S·ª≠ d·ª•ng m√¥i tr∆∞·ªùng ch·ª©a PyTorch/Protnn)
PYTORCH_ENV = "pytorch-env/bin/python" 

# S·ªë l∆∞·ª£ng GPU t·ªëi ƒëa mu·ªën s·ª≠ d·ª•ng
NUM_GPUS = 8
BATCH_SIZE = "1024"
NUM_WORKERS = "4"

def run_worker(gpu_id, command_list):
    """Worker process: Ch·∫°y danh s√°ch c√°c l·ªánh tr√™n GPU ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh."""
    print(f"üöÄ [GPU {gpu_id}] Worker started with {len(command_list)} tasks.")

    for py_env, script, config_path, tta_idx in command_list:
        log_filename = f"gcn_tta_{tta_idx}.log"
        log_path = os.path.join(LOG_DIR, log_filename)
        
        cmd = [
            py_env, script, 
            "--config-path", config_path,
            "--device", str(gpu_id),
            "--run-index", str(tta_idx),
            "--batch-size", BATCH_SIZE,
            "--num-workers", NUM_WORKERS
        ]

        print(f"    ‚ñ∂ [GPU {gpu_id}] Running TTA Index {tta_idx}")
        
        with open(log_path, "w") as f_log:
            try:
                env = os.environ.copy()
                env["PYTHONUNBUFFERED"] = "1"
                subprocess.run(cmd, stdout=f_log, stderr=subprocess.STDOUT, check=True, env=env)
            except subprocess.CalledProcessError:
                f_log.write(f"\n\n[ERROR] Process failed for TTA {tta_idx}.\n")
                print(f"    ‚ùå [GPU {gpu_id}] Failed TTA {tta_idx}! Check logs.")
                return 

    print(f"‚úÖ [GPU {gpu_id}] All tasks completed.")

def main():
    os.makedirs(LOG_DIR, exist_ok=True)

    # 1. ƒê·ªçc Config ƒë·ªÉ bi·∫øt c√≥ bao nhi√™u TTA steps
    print(f"üîç ƒêang ƒë·ªçc config t·ª´ {CONFIG_PATH}...")
    with open(CONFIG_PATH) as f:
        config = yaml.safe_load(f)
    
    # L·∫•y danh s√°ch TTA t·ª´ ontology ƒë·∫ßu ti√™n (th∆∞·ªùng gi·ªëng nhau cho c·∫£ 3)
    # Gi·∫£ ƒë·ªãnh c·∫•u tr√∫c config['gcn']['bp']['tta'] t·ªìn t·∫°i
    first_onto = list(config['gcn'].keys())[0] # th∆∞·ªùng l√† 'bp'
    tta_configs = config['gcn'][first_onto]['tta']
    
    num_tta_tasks = len(tta_configs)
    print(f"üìä T√¨m th·∫•y {num_tta_tasks} c·∫•u h√¨nh TTA c·∫ßn ch·∫°y.")

    # 2. Ph√¢n chia t√°c v·ª• (Round-robin)
    # tasks = { '0': [cmd1, cmd2], '1': [cmd3], ... }
    tasks = {str(i): [] for i in range(NUM_GPUS)}
    
    for k in range(num_tta_tasks):
        gpu_id = str(k % NUM_GPUS) # Chia ƒë·ªÅu theo modulo
        
        # T·∫°o command tuple
        task_info = (PYTORCH_ENV, WORKER_SCRIPT, CONFIG_PATH, k)
        tasks[gpu_id].append(task_info)

    # L·ªçc b·ªè c√°c GPU kh√¥ng c√≥ vi·ªác (n·∫øu √≠t task h∆°n GPU)
    active_tasks = [(gid, cmds) for gid, cmds in tasks.items() if cmds]

    print(f"üöÄ B·∫Øt ƒë·∫ßu ch·∫°y song song tr√™n {len(active_tasks)} GPU...\n")

    # 3. Kh·ªüi ch·∫°y multiprocessing
    processes = []
    for gpu_id, cmds in active_tasks:
        p = multiprocessing.Process(target=run_worker, args=(gpu_id, cmds))
        processes.append(p)
        p.start()
        time.sleep(1) # Delay nh·∫π ƒë·ªÉ tr√°nh load data ·ªì ·∫°t c√πng l√∫c

    # 4. Ch·ªù ho√†n th√†nh
    for p in processes:
        p.join()

    print(f"\nüéâ ƒê√£ ch·∫°y xong t·∫•t c·∫£ c√°c ti·∫øn tr√¨nh! Ki·ªÉm tra k·∫øt qu·∫£ trong folder models/gcn.")

if __name__ == "__main__":
    main()