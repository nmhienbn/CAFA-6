{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKsj0NdKZNiD",
    "outputId": "c645677f-653d-4388-db1a-4ac4bbe1e206"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !pip install -q transformers biopython kaggle\n",
    "# print(\"âœ… ÄÃ£ cÃ i Ä‘áº·t xong thÆ° viá»‡n!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "XyDuqixsZRSx",
    "outputId": "4b0f9ca3-d5d3-4741-db10-8c0546019729"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import files\n",
    "\n",
    "# # Upload file kaggle.json\n",
    "# print(\"Vui lÃ²ng upload file kaggle.json cá»§a báº¡n:\")\n",
    "# files.upload()\n",
    "\n",
    "# # Cáº¥u hÃ¬nh Kaggle API\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Táº£i dá»¯ liá»‡u cuá»™c thi (Sáº½ máº¥t khoáº£ng 1-2 phÃºt)\n",
    "# print(\"â³ Äang táº£i dá»¯ liá»‡u CAFA 6...\")\n",
    "# !kaggle competitions download -c cafa-6-protein-function-prediction\n",
    "# !unzip -q cafa-6-protein-function-prediction.zip -d /content/cafa6_data\n",
    "# print(\"âœ… ÄÃ£ táº£i vÃ  giáº£i nÃ©n dá»¯ liá»‡u táº¡i /content/cafa6_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ CAFA 6 - DUAL MODEL (ANKH + ESM) | Device: cuda\n"
     ]
    }
   ],
   "source": [
    "with open(\"configs/base_model_kfold.yaml\", \"r\") as f:\n",
    "    CONFIG = yaml.safe_load(f)\n",
    "\n",
    "if CONFIG.get(\"DEVICE\", \"auto\") == \"auto\":\n",
    "    CONFIG[\"DEVICE\"] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "CONFIG['ONTOLOGY'] = \"CC\"\n",
    "CONFIG['TOP_TERMS_NPY'] = \"features/top_terms_by_aspect/top_terms_CC.npy\"\n",
    "\n",
    "os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n",
    "print(f\"ðŸš€ CAFA 6 - DUAL MODEL (ANKH + ESM) | Device: {CONFIG['DEVICE']}\")\n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])\n",
    "np.random.seed(CONFIG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MEMORY-SAFE DATASET\n",
    "CHÃŒA KHÃ“A Äá»‚ KHÃ”NG TRÃ€N RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSourceDataset(Dataset):\n",
    "    def __init__(self, embedding_paths_dict, y_tensor=None, indices=None):\n",
    "        self.mmaps = {}\n",
    "        self.keys = list(embedding_paths_dict.keys())\n",
    "\n",
    "        # Load mmap\n",
    "        for name, path in embedding_paths_dict.items():\n",
    "            self.mmaps[name] = np.load(path, mmap_mode='r')\n",
    "\n",
    "        # Base length\n",
    "        first_key = self.keys[0]\n",
    "        self.total_len = len(self.mmaps[first_key])\n",
    "\n",
    "        self.indices = indices if indices is not None else np.arange(self.total_len)\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "\n",
    "        inputs = []\n",
    "        # Load tá»«ng vector -> List of Tensors\n",
    "        for key in self.keys:\n",
    "            vec = torch.from_numpy(self.mmaps[key][real_idx].copy()).float()\n",
    "            inputs.append(vec)\n",
    "\n",
    "        if self.y is not None:\n",
    "            return inputs, self.y[real_idx]\n",
    "        return (inputs,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LOAD DATA & PROCESS LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] Checking Files...\n",
      "   âœ“ Train IDs: 82404\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[1/5] Checking Files...\")\n",
    "train_ids = np.load(CONFIG['TRAIN_ID_PATH'])\n",
    "print(f\"   âœ“ Train IDs: {len(train_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] Processing Labels (IA Strategy)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n[2/5] Processing Labels (IA Strategy)...\")\n",
    "# 1. Load Terms & IA\n",
    "df_terms = pd.read_csv(CONFIG['TRAIN_TERMS'], sep='\\t', header=0,\n",
    "                       names=['EntryID', 'term', 'aspect'])\n",
    "df_ia = pd.read_csv(CONFIG['IA_FILE'], sep='\\t', names=['term', 'ia'])\n",
    "ia_dict = dict(zip(df_ia['term'], df_ia['ia']))\n",
    "\n",
    "# 2. TÃ­nh Score\n",
    "# map ontology -> aspect char\n",
    "ONTOLOGY2ASPECT = {'MF': 'F', 'BP': 'P', 'CC': 'C'}\n",
    "aspect_char = ONTOLOGY2ASPECT[CONFIG['ONTOLOGY']]\n",
    "\n",
    "# chá»‰ giá»¯ terms thuá»™c ontology nÃ y\n",
    "df_terms_aspect = df_terms[df_terms['aspect'] == aspect_char]\n",
    "\n",
    "# load top_terms cho ontology nÃ y\n",
    "top_terms = np.load(CONFIG['TOP_TERMS_NPY'], allow_pickle=True).tolist()\n",
    "\n",
    "# lá»c láº¡i theo top_terms\n",
    "df_filtered = df_terms_aspect[df_terms_aspect['term'].isin(top_terms)]\n",
    "id_to_terms = df_filtered.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "# Dá»n dáº¹p\n",
    "del df_terms, df_terms_aspect, df_filtered\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PREPARE LABELS\n",
    "(RAM OPTIMIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] Preparing Labels (Sparse Mode)...\n",
      "   â³ Converting Labels to Tensor...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82404, 2651)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n[3/5] Preparing Labels (Sparse Mode)...\")\n",
    "\n",
    "# 1. Sparse MLB\n",
    "mlb = MultiLabelBinarizer(classes=top_terms, sparse_output=True)\n",
    "mlb.fit([top_terms])\n",
    "\n",
    "# 2. Transform -> Sparse Matrix\n",
    "y_labels_list = [id_to_terms.get(pid, []) for pid in train_ids]\n",
    "y_train_sparse = mlb.transform(y_labels_list)\n",
    "del y_labels_list, train_ids # XÃ³a ID list khÃ´ng dÃ¹ng ná»¯a\n",
    "gc.collect()\n",
    "\n",
    "# 3. Weights (Optional)\n",
    "# Náº¿u dÃ¹ng IA weight thÃ¬ giá»¯, náº¿u muá»‘n model tá»± há»c thÃ¬ comment dÃ²ng nÃ y vÃ  bá» pos_weight trong Loss\n",
    "weights_list = [ia_dict.get(t, 0.0) for t in mlb.classes_]\n",
    "pos_weight_tensor = torch.tensor(weights_list, dtype=torch.float32).to(CONFIG['DEVICE'])\n",
    "\n",
    "# 4. Convert to Dense Float32 & Label Smoothing\n",
    "print(\"   â³ Converting Labels to Tensor...\")\n",
    "# Convert tá»«ng pháº§n nhá» hoáº·c convert háº¿t náº¿u RAM > 12GB (vá»›i 80k row x 10k col float32 ~ 3.2GB -> á»”n)\n",
    "# true labels 0/1 (dÃ¹ng cho tuning F-max)\n",
    "y_train_binary = y_train_sparse.astype(np.float32).toarray()\n",
    "y_true_np = y_train_binary.copy()   # lÆ°u láº¡i cho threshold tuning\n",
    "y_train_tensor = torch.from_numpy(y_train_binary)\n",
    "\n",
    "if CONFIG['LABEL_SMOOTHING'] > 0:\n",
    "    y_train_tensor.mul_(1 - CONFIG['LABEL_SMOOTHING']).add_(CONFIG['LABEL_SMOOTHING'] / len(top_terms))\n",
    "\n",
    "del y_train_sparse\n",
    "gc.collect()\n",
    "\n",
    "y_true_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_for_strat shape: (82404, 32)\n"
     ]
    }
   ],
   "source": [
    "# ----- chá»n nhÃ£n phá»• biáº¿n nháº¥t Ä‘á»ƒ stratification -----\n",
    "label_freq = y_true_np.sum(axis=0)              # (n_labels,)\n",
    "order = np.argsort(-label_freq)                 # sort desc\n",
    "top_strat_labels = order[:CONFIG['N_LABELS_STRAT']]\n",
    "\n",
    "y_for_strat = y_true_np[:, top_strat_labels]    # (n_samples, N_LABELS_STRAT)\n",
    "print('y_for_strat shape:', y_for_strat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CREATE DATA LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] Creating DataLoaders...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/5] Creating DataLoaders...\")\n",
    "\n",
    "train_paths = {k: v['train'] for k, v in CONFIG['EMBEDDINGS'].items()}\n",
    "\n",
    "# táº¡o dataset táº¡m Ä‘á»ƒ láº¥y dimensionality\n",
    "tmp_dataset = MultiSourceDataset(train_paths)\n",
    "sample_inputs, = tmp_dataset[0]   # vÃ¬ y=None -> __getitem__ tráº£ (inputs,)\n",
    "INPUT_DIMS_LIST = [x.shape[0] for x in sample_inputs]\n",
    "del tmp_dataset\n",
    "\n",
    "n_samples, n_labels = y_true_np.shape\n",
    "indices = np.arange(n_samples)\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(\n",
    "    n_splits=CONFIG['N_FOLDS'],\n",
    "    shuffle=True,\n",
    "    random_state=CONFIG['SEED']\n",
    ")\n",
    "\n",
    "# OOF predictions\n",
    "oof_pred = np.zeros((n_samples, n_labels), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODEL & TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_dim, layers_config, dropout):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # 1. LAYER NORM Äáº¦U VÃ€O (Báº®T BUá»˜C)\n",
    "        # Äá»ƒ cÃ¢n báº±ng 'Ã¢m lÆ°á»£ng' giá»¯a ESM (hÃ©t to) vÃ  Ankh (nÃ³i nhá»)\n",
    "        layers.append(nn.LayerNorm(in_dim))\n",
    "\n",
    "        prev_dim = in_dim\n",
    "        for i, dim in enumerate(layers_config):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, dim),\n",
    "                nn.BatchNorm1d(dim), # á»”n Ä‘á»‹nh training\n",
    "                nn.GELU(),           # Hiá»‡n Ä‘áº¡i hÆ¡n ReLU\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.out_dim = prev_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module lá»c nhiá»…u (Attention)\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block Ä‘á»ƒ lá»c nhiá»…u sau khi gá»™p\"\"\"\n",
    "    def __init__(self, in_dim, reduction=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim // reduction, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim // reduction, in_dim, bias=False),\n",
    "            nn.Sigmoid() # Táº¡o ra mask tá»« 0 Ä‘áº¿n 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, Dim]\n",
    "        # Attention weight: [Batch, Dim]\n",
    "        w = self.fc(x)\n",
    "        # NhÃ¢n trá»ng sá»‘ vÃ o x: CÃ¡i nÃ o quan trá»ng thÃ¬ giá»¯, rÃ¡c thÃ¬ nhÃ¢n vá»›i 0\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, input_dims_list, encoder_layers, dropout, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.fusion_input_dim = 0\n",
    "\n",
    "        print(\"\\nðŸ—ï¸ Building Advanced Architecture:\")\n",
    "\n",
    "        # 1. XÃ¢y dá»±ng cÃ¡c nhÃ¡nh Encoder\n",
    "        for i, in_dim in enumerate(input_dims_list):\n",
    "            print(f\"   âž¤ Branch {i+1}: Input {in_dim} -> Output {encoder_layers[-1]}\")\n",
    "            enc = EncoderBlock(in_dim, encoder_layers, dropout)\n",
    "            self.encoders.append(enc)\n",
    "            self.fusion_input_dim += enc.out_dim\n",
    "\n",
    "        print(f\"   âž¤ Fusion Dim: {self.fusion_input_dim}\")\n",
    "\n",
    "        # 2. SE-Block (Bá»™ lá»c thÃ´ng minh)\n",
    "        self.attention_filter = SEBlock(self.fusion_input_dim)\n",
    "\n",
    "        # 3. Layer tá»•ng há»£p cuá»‘i cÃ¹ng\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.fusion_input_dim),\n",
    "            nn.Linear(self.fusion_input_dim, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            # ThÃªm má»™t lá»›p ná»¯a Ä‘á»ƒ tÄƒng kháº£ nÄƒng há»c\n",
    "            nn.Linear(512, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs_list):\n",
    "        features = []\n",
    "        # Äi qua tá»«ng nhÃ¡nh\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            feat = encoder(inputs_list[i])\n",
    "            features.append(feat)\n",
    "\n",
    "        # Gá»™p láº¡i (Concatenate)\n",
    "        combined = torch.cat(features, dim=1)\n",
    "\n",
    "        # Lá»ŒC NHIá»„U (Äiá»ƒm khÃ¡c biá»‡t lá»›n nháº¥t)\n",
    "        # Máº¡ng sáº½ tá»± há»c cÃ¡ch \"táº¯t tiáº¿ng\" cÃ¡c Ä‘áº·c trÆ°ng rÃ¡c tá»« ProtT5 náº¿u nÃ³ tháº¥y khÃ´ng cáº§n thiáº¿t\n",
    "        refined = self.attention_filter(combined)\n",
    "\n",
    "        return self.head(refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "455a63b70833456bbb910351a7fa4f0c",
      "8a1a69e89b6b4073bcade374469d7bec",
      "ae345da5f78c4511a438386a8003b988",
      "5b0cd2b73ddd4e058e4c8162322e08c2",
      "a8ff28bbc8ab445493d4680da28ab271",
      "2ebe17650b094512b1d2fffde6cada83",
      "337ec8994f00422eb3ddc942876e99fc",
      "e5aa8e8a55834fbbb7e5120b961484f6",
      "881517707ea7414a8b54bb04b5170ed9",
      "8f47760438f04fc0b6c953f15407da76",
      "fe99a758b1a342b49314c46778564927"
     ]
    },
    "id": "1xA1jFwVZRko",
    "outputId": "2f1274f6-e6d0-4aab-eb2a-74d70190eae1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/5] Building Model...\n",
      "=== Fold 0 ===\n",
      "\n",
      "ðŸ—ï¸ Building Advanced Architecture:\n",
      "   âž¤ Branch 1: Input 768 -> Output 512\n",
      "   âž¤ Branch 2: Input 1280 -> Output 512\n",
      "   âž¤ Branch 3: Input 1024 -> Output 512\n",
      "   âž¤ Fusion Dim: 1536\n",
      "\n",
      "ðŸš€ START TRAINING (50 Epochs)...\n",
      "Fold 0 | Epoch 1/50 | train 0.0381 | val 0.0063\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 2/50 | train 0.0066 | val 0.0061\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 3/50 | train 0.0063 | val 0.0059\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 4/50 | train 0.0060 | val 0.0057\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 5/50 | train 0.0058 | val 0.0055\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 6/50 | train 0.0056 | val 0.0054\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 7/50 | train 0.0055 | val 0.0053\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 8/50 | train 0.0054 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 9/50 | train 0.0053 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 10/50 | train 0.0052 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 11/50 | train 0.0051 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 12/50 | train 0.0050 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 13/50 | train 0.0049 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 14/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 15/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 16/50 | train 0.0047 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 17/50 | train 0.0046 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 18/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 19/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 20/50 | train 0.0045 | val 0.0047\n",
      "Fold 0 | Epoch 21/50 | train 0.0044 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 22/50 | train 0.0044 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 23/50 | train 0.0044 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 24/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 25/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 26/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 27/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 28/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 29/50 | train 0.0041 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 30/50 | train 0.0041 | val 0.0046\n",
      "Fold 0 | Epoch 31/50 | train 0.0041 | val 0.0046\n",
      "Fold 0 | Epoch 32/50 | train 0.0040 | val 0.0046\n",
      "Fold 0 | Epoch 33/50 | train 0.0040 | val 0.0046\n",
      "Fold 0 | Epoch 34/50 | train 0.0039 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 0 | Epoch 35/50 | train 0.0039 | val 0.0046\n",
      "Fold 0 | Epoch 36/50 | train 0.0038 | val 0.0046\n",
      "Fold 0 | Epoch 37/50 | train 0.0038 | val 0.0046\n",
      "Fold 0 | Epoch 38/50 | train 0.0038 | val 0.0046\n",
      "Fold 0 | Epoch 39/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 40/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 41/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 42/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 43/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 44/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 45/50 | train 0.0036 | val 0.0046\n",
      "Fold 0 | Epoch 46/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 47/50 | train 0.0037 | val 0.0046\n",
      "Fold 0 | Epoch 48/50 | train 0.0036 | val 0.0046\n",
      "Fold 0 | Epoch 49/50 | train 0.0036 | val 0.0046\n",
      "Fold 0 | Epoch 50/50 | train 0.0036 | val 0.0046\n",
      "Infer OOF for fold 0\n",
      "=== Fold 1 ===\n",
      "\n",
      "ðŸ—ï¸ Building Advanced Architecture:\n",
      "   âž¤ Branch 1: Input 768 -> Output 512\n",
      "   âž¤ Branch 2: Input 1280 -> Output 512\n",
      "   âž¤ Branch 3: Input 1024 -> Output 512\n",
      "   âž¤ Fusion Dim: 1536\n",
      "\n",
      "ðŸš€ START TRAINING (50 Epochs)...\n",
      "Fold 1 | Epoch 1/50 | train 0.0388 | val 0.0062\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 2/50 | train 0.0066 | val 0.0060\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 3/50 | train 0.0063 | val 0.0057\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 4/50 | train 0.0061 | val 0.0056\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 5/50 | train 0.0059 | val 0.0054\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 6/50 | train 0.0057 | val 0.0053\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 7/50 | train 0.0055 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 8/50 | train 0.0054 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 9/50 | train 0.0053 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 10/50 | train 0.0052 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 11/50 | train 0.0051 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 12/50 | train 0.0050 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 13/50 | train 0.0050 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 14/50 | train 0.0049 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 15/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 16/50 | train 0.0047 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 17/50 | train 0.0047 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 18/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 19/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 20/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 21/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 22/50 | train 0.0045 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 23/50 | train 0.0044 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 24/50 | train 0.0044 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 25/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 26/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 27/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 28/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 29/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 30/50 | train 0.0041 | val 0.0046\n",
      "Fold 1 | Epoch 31/50 | train 0.0041 | val 0.0046\n",
      "Fold 1 | Epoch 32/50 | train 0.0041 | val 0.0046\n",
      "Fold 1 | Epoch 33/50 | train 0.0041 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 34/50 | train 0.0040 | val 0.0046\n",
      "Fold 1 | Epoch 35/50 | train 0.0040 | val 0.0046\n",
      "Fold 1 | Epoch 36/50 | train 0.0040 | val 0.0045\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 37/50 | train 0.0040 | val 0.0046\n",
      "Fold 1 | Epoch 38/50 | train 0.0040 | val 0.0045\n",
      "  â­ New Best Model!\n",
      "Fold 1 | Epoch 39/50 | train 0.0039 | val 0.0045\n",
      "Fold 1 | Epoch 40/50 | train 0.0039 | val 0.0045\n",
      "Fold 1 | Epoch 41/50 | train 0.0039 | val 0.0046\n",
      "Fold 1 | Epoch 42/50 | train 0.0039 | val 0.0046\n",
      "Fold 1 | Epoch 43/50 | train 0.0038 | val 0.0045\n",
      "Fold 1 | Epoch 44/50 | train 0.0037 | val 0.0045\n",
      "Fold 1 | Epoch 45/50 | train 0.0037 | val 0.0046\n",
      "Fold 1 | Epoch 46/50 | train 0.0037 | val 0.0046\n",
      "Fold 1 | Epoch 47/50 | train 0.0036 | val 0.0046\n",
      "Fold 1 | Epoch 48/50 | train 0.0036 | val 0.0046\n",
      "Fold 1 | Epoch 49/50 | train 0.0036 | val 0.0046\n",
      "Fold 1 | Epoch 50/50 | train 0.0036 | val 0.0046\n",
      "Infer OOF for fold 1\n",
      "=== Fold 2 ===\n",
      "\n",
      "ðŸ—ï¸ Building Advanced Architecture:\n",
      "   âž¤ Branch 1: Input 768 -> Output 512\n",
      "   âž¤ Branch 2: Input 1280 -> Output 512\n",
      "   âž¤ Branch 3: Input 1024 -> Output 512\n",
      "   âž¤ Fusion Dim: 1536\n",
      "\n",
      "ðŸš€ START TRAINING (50 Epochs)...\n",
      "Fold 2 | Epoch 1/50 | train 0.0385 | val 0.0063\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 2/50 | train 0.0066 | val 0.0060\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 3/50 | train 0.0063 | val 0.0058\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 4/50 | train 0.0060 | val 0.0056\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 5/50 | train 0.0058 | val 0.0055\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 6/50 | train 0.0056 | val 0.0053\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 7/50 | train 0.0055 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 8/50 | train 0.0053 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 9/50 | train 0.0052 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 10/50 | train 0.0051 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 11/50 | train 0.0050 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 12/50 | train 0.0050 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 13/50 | train 0.0049 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 14/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 15/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 16/50 | train 0.0047 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 17/50 | train 0.0046 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 18/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 19/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 20/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 21/50 | train 0.0044 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 22/50 | train 0.0044 | val 0.0047\n",
      "Fold 2 | Epoch 23/50 | train 0.0043 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 24/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 25/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 26/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 27/50 | train 0.0042 | val 0.0046\n",
      "Fold 2 | Epoch 28/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 29/50 | train 0.0041 | val 0.0046\n",
      "Fold 2 | Epoch 30/50 | train 0.0041 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 31/50 | train 0.0040 | val 0.0046\n",
      "Fold 2 | Epoch 32/50 | train 0.0040 | val 0.0046\n",
      "Fold 2 | Epoch 33/50 | train 0.0040 | val 0.0046\n",
      "Fold 2 | Epoch 34/50 | train 0.0040 | val 0.0046\n",
      "Fold 2 | Epoch 35/50 | train 0.0039 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 2 | Epoch 36/50 | train 0.0038 | val 0.0046\n",
      "Fold 2 | Epoch 37/50 | train 0.0038 | val 0.0046\n",
      "Fold 2 | Epoch 38/50 | train 0.0038 | val 0.0046\n",
      "Fold 2 | Epoch 39/50 | train 0.0038 | val 0.0046\n",
      "Fold 2 | Epoch 40/50 | train 0.0037 | val 0.0046\n",
      "Fold 2 | Epoch 41/50 | train 0.0037 | val 0.0046\n",
      "Fold 2 | Epoch 42/50 | train 0.0037 | val 0.0046\n",
      "Fold 2 | Epoch 43/50 | train 0.0037 | val 0.0046\n",
      "Fold 2 | Epoch 44/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 45/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 46/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 47/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 48/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 49/50 | train 0.0036 | val 0.0046\n",
      "Fold 2 | Epoch 50/50 | train 0.0036 | val 0.0046\n",
      "Infer OOF for fold 2\n",
      "=== Fold 3 ===\n",
      "\n",
      "ðŸ—ï¸ Building Advanced Architecture:\n",
      "   âž¤ Branch 1: Input 768 -> Output 512\n",
      "   âž¤ Branch 2: Input 1280 -> Output 512\n",
      "   âž¤ Branch 3: Input 1024 -> Output 512\n",
      "   âž¤ Fusion Dim: 1536\n",
      "\n",
      "ðŸš€ START TRAINING (50 Epochs)...\n",
      "Fold 3 | Epoch 1/50 | train 0.0381 | val 0.0062\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 2/50 | train 0.0066 | val 0.0060\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 3/50 | train 0.0063 | val 0.0058\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 4/50 | train 0.0060 | val 0.0056\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 5/50 | train 0.0058 | val 0.0055\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 6/50 | train 0.0056 | val 0.0053\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 7/50 | train 0.0055 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 8/50 | train 0.0054 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 9/50 | train 0.0052 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 10/50 | train 0.0051 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 11/50 | train 0.0051 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 12/50 | train 0.0050 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 13/50 | train 0.0049 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 14/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 15/50 | train 0.0048 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 16/50 | train 0.0047 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 17/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 18/50 | train 0.0046 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 19/50 | train 0.0045 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 20/50 | train 0.0045 | val 0.0047\n",
      "Fold 3 | Epoch 21/50 | train 0.0044 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 22/50 | train 0.0044 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 23/50 | train 0.0044 | val 0.0046\n",
      "Fold 3 | Epoch 24/50 | train 0.0043 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 25/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 26/50 | train 0.0042 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 27/50 | train 0.0042 | val 0.0046\n",
      "Fold 3 | Epoch 28/50 | train 0.0041 | val 0.0046\n",
      "Fold 3 | Epoch 29/50 | train 0.0041 | val 0.0046\n",
      "Fold 3 | Epoch 30/50 | train 0.0041 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 31/50 | train 0.0041 | val 0.0046\n",
      "Fold 3 | Epoch 32/50 | train 0.0040 | val 0.0046\n",
      "Fold 3 | Epoch 33/50 | train 0.0040 | val 0.0046\n",
      "Fold 3 | Epoch 34/50 | train 0.0040 | val 0.0046\n",
      "Fold 3 | Epoch 35/50 | train 0.0039 | val 0.0046\n",
      "Fold 3 | Epoch 36/50 | train 0.0039 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 37/50 | train 0.0038 | val 0.0046\n",
      "Fold 3 | Epoch 38/50 | train 0.0038 | val 0.0046\n",
      "Fold 3 | Epoch 39/50 | train 0.0038 | val 0.0046\n",
      "Fold 3 | Epoch 40/50 | train 0.0038 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 3 | Epoch 41/50 | train 0.0037 | val 0.0046\n",
      "Fold 3 | Epoch 42/50 | train 0.0037 | val 0.0046\n",
      "Fold 3 | Epoch 43/50 | train 0.0037 | val 0.0046\n",
      "Fold 3 | Epoch 44/50 | train 0.0037 | val 0.0046\n",
      "Fold 3 | Epoch 45/50 | train 0.0036 | val 0.0046\n",
      "Fold 3 | Epoch 46/50 | train 0.0036 | val 0.0046\n",
      "Fold 3 | Epoch 47/50 | train 0.0036 | val 0.0046\n",
      "Fold 3 | Epoch 48/50 | train 0.0036 | val 0.0046\n",
      "Fold 3 | Epoch 49/50 | train 0.0036 | val 0.0046\n",
      "Fold 3 | Epoch 50/50 | train 0.0036 | val 0.0046\n",
      "Infer OOF for fold 3\n",
      "=== Fold 4 ===\n",
      "\n",
      "ðŸ—ï¸ Building Advanced Architecture:\n",
      "   âž¤ Branch 1: Input 768 -> Output 512\n",
      "   âž¤ Branch 2: Input 1280 -> Output 512\n",
      "   âž¤ Branch 3: Input 1024 -> Output 512\n",
      "   âž¤ Fusion Dim: 1536\n",
      "\n",
      "ðŸš€ START TRAINING (50 Epochs)...\n",
      "Fold 4 | Epoch 1/50 | train 0.0378 | val 0.0064\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 2/50 | train 0.0067 | val 0.0061\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 3/50 | train 0.0063 | val 0.0059\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 4/50 | train 0.0060 | val 0.0057\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 5/50 | train 0.0058 | val 0.0055\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 6/50 | train 0.0056 | val 0.0054\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 7/50 | train 0.0055 | val 0.0053\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 8/50 | train 0.0053 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 9/50 | train 0.0052 | val 0.0052\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 10/50 | train 0.0051 | val 0.0051\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 11/50 | train 0.0050 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 12/50 | train 0.0050 | val 0.0050\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 13/50 | train 0.0049 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 14/50 | train 0.0048 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 15/50 | train 0.0047 | val 0.0049\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 16/50 | train 0.0047 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 17/50 | train 0.0046 | val 0.0048\n",
      "Fold 4 | Epoch 18/50 | train 0.0045 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 19/50 | train 0.0045 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 20/50 | train 0.0044 | val 0.0048\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 21/50 | train 0.0044 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 22/50 | train 0.0044 | val 0.0047\n",
      "Fold 4 | Epoch 23/50 | train 0.0043 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 24/50 | train 0.0042 | val 0.0047\n",
      "Fold 4 | Epoch 25/50 | train 0.0042 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 26/50 | train 0.0042 | val 0.0047\n",
      "Fold 4 | Epoch 27/50 | train 0.0041 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 28/50 | train 0.0041 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 29/50 | train 0.0041 | val 0.0047\n",
      "Fold 4 | Epoch 30/50 | train 0.0041 | val 0.0047\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 31/50 | train 0.0040 | val 0.0047\n",
      "Fold 4 | Epoch 32/50 | train 0.0040 | val 0.0047\n",
      "Fold 4 | Epoch 33/50 | train 0.0040 | val 0.0047\n",
      "Fold 4 | Epoch 34/50 | train 0.0039 | val 0.0047\n",
      "Fold 4 | Epoch 35/50 | train 0.0038 | val 0.0046\n",
      "  â­ New Best Model!\n",
      "Fold 4 | Epoch 36/50 | train 0.0038 | val 0.0046\n",
      "Fold 4 | Epoch 37/50 | train 0.0038 | val 0.0046\n",
      "Fold 4 | Epoch 38/50 | train 0.0037 | val 0.0047\n",
      "Fold 4 | Epoch 39/50 | train 0.0037 | val 0.0047\n",
      "Fold 4 | Epoch 40/50 | train 0.0037 | val 0.0047\n",
      "Fold 4 | Epoch 41/50 | train 0.0037 | val 0.0047\n",
      "Fold 4 | Epoch 42/50 | train 0.0036 | val 0.0047\n",
      "Fold 4 | Epoch 43/50 | train 0.0036 | val 0.0047\n",
      "Fold 4 | Epoch 44/50 | train 0.0036 | val 0.0047\n",
      "Fold 4 | Epoch 45/50 | train 0.0036 | val 0.0047\n",
      "Fold 4 | Epoch 46/50 | train 0.0036 | val 0.0047\n",
      "Fold 4 | Epoch 47/50 | train 0.0036 | val 0.0047\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     45\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     49\u001b[0m avg_train \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/optim/adamw.py:477\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m differentiable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_foreach ops don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m grad_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m found_inf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m grouped_tensors \u001b[38;5;241m=\u001b[39m \u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (device_params, device_grads, device_exp_avgs, device_exp_avg_sqs,\n\u001b[1;32m    480\u001b[0m      device_max_exp_avg_sqs, device_state_steps) \u001b[38;5;129;01min\u001b[39;00m grouped_tensors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m maximize:\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cafa/lib/python3.10/site-packages/torch/utils/_foreach_utils.py:30\u001b[0m, in \u001b[0;36m_group_tensors_by_device_and_dtype\u001b[0;34m(tensorlistlist, with_indices)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tensorlistlist[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     29\u001b[0m     key \u001b[38;5;241m=\u001b[39m (t\u001b[38;5;241m.\u001b[39mdevice, t\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# a tensorlist may be empty/None\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m tensorlistlist[j]:\n\u001b[1;32m     33\u001b[0m             per_device_and_dtype_tensors[key][j]\u001b[38;5;241m.\u001b[39mappend(tensorlistlist[j][i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tornado.general:Got events for closed stream <zmq.eventloop.zmqstream.ZMQStream object at 0x7f5e06e317b0>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/5] Building Model...\")\n",
    "\n",
    "# Loss & Optimizer\n",
    "# CÃ³ thá»ƒ thá»­ bá» pos_weight náº¿u tháº¥y loss dao Ä‘á»™ng quÃ¡ máº¡nh\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(mskf.split(np.zeros(n_samples), y_for_strat)):\n",
    "    print(f'=== Fold {fold} ===')\n",
    "    train_dataset = MultiSourceDataset(train_paths, y_train_tensor, indices=train_idx)\n",
    "    val_dataset   = MultiSourceDataset(train_paths, y_train_tensor, indices=val_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['BATCH_SIZE'],\n",
    "        shuffle=True, num_workers=2\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=CONFIG['BATCH_SIZE'],\n",
    "        shuffle=False, num_workers=2\n",
    "    )\n",
    "    model = MultiModalNet(\n",
    "        input_dims_list = INPUT_DIMS_LIST,\n",
    "        encoder_layers  = CONFIG['ENCODER_LAYERS'],\n",
    "        dropout         = CONFIG['DROPOUT_RATE'],\n",
    "        num_classes     = len(top_terms) # DÃ¹ng sá»‘ lÆ°á»£ng thá»±c táº¿ sau lá»c\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['LEARNING_RATE'], weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    print(f\"\\nðŸš€ START TRAINING ({CONFIG['EPOCHS']} Epochs)...\")\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = f\"{CONFIG['SAVE_DIR']}/best_fold{fold}_{CONFIG['ONTOLOGY']}.pth\"\n",
    "    \n",
    "    for epoch in range(CONFIG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_b, y_b in train_loader:\n",
    "            X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n",
    "            y_b = y_b.to(CONFIG['DEVICE'])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_b)\n",
    "            loss = criterion(logits, y_b)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_b, y_b in val_loader:\n",
    "                X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n",
    "                y_b = y_b.to(CONFIG['DEVICE'])\n",
    "                logits = model(X_b)\n",
    "                loss = criterion(logits, y_b)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        scheduler.step(avg_val)\n",
    "\n",
    "        print(f\"Fold {fold} | Epoch {epoch+1}/{CONFIG['EPOCHS']} \"\n",
    "              f\"| train {avg_train:.4f} | val {avg_val:.4f}\")\n",
    "\n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(\"  â­ New Best Model!\")\n",
    "\n",
    "    # ===== OOF prediction cho fold nÃ y =====\n",
    "    print(f'Infer OOF for fold {fold}')\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=CONFIG['DEVICE']))\n",
    "    model.eval()\n",
    "\n",
    "    fold_val_pred = np.zeros((len(val_idx), n_labels), dtype=np.float32)\n",
    "    pos = 0\n",
    "    with torch.no_grad():\n",
    "        for X_b, y_b in DataLoader(\n",
    "            val_dataset, batch_size=CONFIG['BATCH_SIZE'],\n",
    "            shuffle=False, num_workers=2\n",
    "        ):\n",
    "            X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n",
    "            logits = model(X_b)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            bs = probs.shape[0]\n",
    "            fold_val_pred[pos:pos+bs] = probs\n",
    "            pos += bs\n",
    "\n",
    "    oof_pred[val_idx] = fold_val_pred\n",
    "\n",
    "    del train_loader, val_loader, train_dataset, val_dataset, model, optimizer, scheduler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# lÆ°u láº¡i Ä‘á»ƒ debug / dÃ¹ng ngoÃ i\n",
    "np.save(f\"{CONFIG['SAVE_DIR']}/oof_pred_{CONFIG['ONTOLOGY']}.npy\", oof_pred)\n",
    "np.save(f\"{CONFIG['SAVE_DIR']}/y_true_{CONFIG['ONTOLOGY']}.npy\", y_true_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. INFERENCE (STREAMING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_fmax_threshold(y_true, y_score, num_thresholds=99):\n",
    "    thresholds = np.linspace(0.01, 0.99, num_thresholds)\n",
    "    best_t, best_f = 0.3, 0.0\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_score >= t).astype(np.int8)\n",
    "\n",
    "        tp = (y_pred * y_true).sum()\n",
    "        fp = (y_pred * (1 - y_true)).sum()\n",
    "        fn = ((1 - y_pred) * y_true).sum()\n",
    "\n",
    "        if tp == 0:\n",
    "            continue\n",
    "\n",
    "        p = tp / (tp + fp)\n",
    "        r = tp / (tp + fn)\n",
    "        f = 2 * p * r / (p + r)\n",
    "\n",
    "        if f > best_f:\n",
    "            best_f = f\n",
    "            best_t = t\n",
    "\n",
    "    return best_t, best_f\n",
    "\n",
    "thr, fmax = tune_fmax_threshold(y_true_np, oof_pred)\n",
    "print(f\"[{CONFIG['ONTOLOGY']}] Best threshold = {thr:.4f}, Fmax = {fmax:.4f}\")\n",
    "\n",
    "thr_path = f\"{CONFIG['SAVE_DIR']}/thr_{CONFIG['ONTOLOGY']}.txt\"\n",
    "with open(thr_path, 'w') as f:\n",
    "    f.write(f\"{thr:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference cho ontology hiá»‡n táº¡i ===\n",
    "\n",
    "test_paths = {k: v['test'] for k, v in CONFIG['EMBEDDINGS'].items()}\n",
    "test_ids = np.load(CONFIG['TEST_ID_PATH'])\n",
    "\n",
    "test_dataset = MultiSourceDataset(test_paths)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=CONFIG['BATCH_SIZE'] * 2,\n",
    "    shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# load cÃ¡c model tá»«ng fold\n",
    "models = []\n",
    "for fold in range(CONFIG['N_FOLDS']):\n",
    "    model_path = f\"{CONFIG['SAVE_DIR']}/best_fold{fold}_{CONFIG['ONTOLOGY']}.pth\"\n",
    "    m = MultiModalNet(\n",
    "        input_dims_list=INPUT_DIMS_LIST,\n",
    "        encoder_layers=CONFIG['ENCODER_LAYERS'],\n",
    "        dropout=CONFIG['DROPOUT_RATE'],\n",
    "        num_classes=len(top_terms)\n",
    "    ).to(CONFIG['DEVICE'])\n",
    "    m.load_state_dict(torch.load(model_path, map_location=CONFIG['DEVICE']))\n",
    "    m.eval()\n",
    "    models.append(m)\n",
    "\n",
    "# load threshold Ä‘Ã£ tune\n",
    "with open(f\"{CONFIG['SAVE_DIR']}/thr_{CONFIG['ONTOLOGY']}.txt\") as f:\n",
    "    THR = float(f.read().strip())\n",
    "\n",
    "submission_path = f\"{CONFIG['SAVE_DIR']}/submission_{CONFIG['ONTOLOGY']}.tsv\"\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "n_predictions = 0\n",
    "\n",
    "with open(submission_path, 'w') as f:\n",
    "    current_idx = 0\n",
    "    with torch.no_grad():\n",
    "        for (X_b,) in tqdm(test_loader, desc=f\"Inference {CONFIG['ONTOLOGY']}\"):\n",
    "            X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n",
    "\n",
    "            # ensemble trung bÃ¬nh logits cá»§a 5 fold\n",
    "            logits_sum = None\n",
    "            for m in models:\n",
    "                logits = m(X_b)\n",
    "                logits_sum = logits if logits_sum is None else logits_sum + logits\n",
    "            logits_avg = logits_sum / len(models)\n",
    "\n",
    "            probs_batch = torch.sigmoid(logits_avg).cpu().numpy()\n",
    "\n",
    "            ids_batch = test_ids[current_idx: current_idx + len(probs_batch)]\n",
    "            current_idx += len(probs_batch)\n",
    "\n",
    "            for i, pid in enumerate(ids_batch):\n",
    "                probs = probs_batch[i]\n",
    "\n",
    "                top_k = CONFIG['MAX_PREDS_PER_PROTEIN']\n",
    "                ind = np.argpartition(probs, -top_k)[-top_k:]\n",
    "                ind = ind[np.argsort(probs[ind])][::-1]\n",
    "\n",
    "                for idx in ind:\n",
    "                    score = probs[idx]\n",
    "                    if score >= THR:     # dÃ¹ng threshold F-max\n",
    "                        f.write(f\"{pid}\\t{top_terms[idx]}\\t{score:.3f}\\n\")\n",
    "                        n_predictions += 1\n",
    "\n",
    "print(f\"{CONFIG['ONTOLOGY']} done, {n_predictions} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfKYzKqwei36",
    "outputId": "79528daf-7acd-4c74-8f15-f4fd43cf4eb6"
   },
   "outputs": [],
   "source": [
    "# # Cháº¡y lá»‡nh nÃ y trong má»™t cell má»›i\n",
    "# !kaggle competitions submit \\\n",
    "#     -c cafa-6-protein-function-prediction \\\n",
    "#     -f /content/drive/MyDrive/CAFA6_Results/prott5_esm2_ankh_Run/submission.tsv \\\n",
    "#     -m \"esm2 ankh prot t5 new model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-a9eVb5FStU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (cafa)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2ebe17650b094512b1d2fffde6cada83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "337ec8994f00422eb3ddc942876e99fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "455a63b70833456bbb910351a7fa4f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a1a69e89b6b4073bcade374469d7bec",
       "IPY_MODEL_ae345da5f78c4511a438386a8003b988",
       "IPY_MODEL_5b0cd2b73ddd4e058e4c8162322e08c2"
      ],
      "layout": "IPY_MODEL_a8ff28bbc8ab445493d4680da28ab271"
     }
    },
    "5b0cd2b73ddd4e058e4c8162322e08c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f47760438f04fc0b6c953f15407da76",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe99a758b1a342b49314c46778564927",
      "value": "â€‡877/877â€‡[00:42&lt;00:00,â€‡26.13it/s]"
     }
    },
    "881517707ea7414a8b54bb04b5170ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a1a69e89b6b4073bcade374469d7bec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ebe17650b094512b1d2fffde6cada83",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_337ec8994f00422eb3ddc942876e99fc",
      "value": "Inference:â€‡100%"
     }
    },
    "8f47760438f04fc0b6c953f15407da76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8ff28bbc8ab445493d4680da28ab271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae345da5f78c4511a438386a8003b988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5aa8e8a55834fbbb7e5120b961484f6",
      "max": 877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_881517707ea7414a8b54bb04b5170ed9",
      "value": 877
     }
    },
    "e5aa8e8a55834fbbb7e5120b961484f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe99a758b1a342b49314c46778564927": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
