{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RWuBvKFQQQeTmcicgX1HGtINRBe7HF5_","timestamp":1764406804022}],"gpuType":"T4","authorship_tag":"ABX9TyOyRv+NvD84fYUKZTjo+UbN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb77557fa7644c038cf75f85339e40a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe2704f20cde47259ecd417f8c2bc7fe","IPY_MODEL_2d9fa8ffc5c54030a2c999fcf6c12afa","IPY_MODEL_450eb8e8879d4795bb025d6d42e30f1f"],"layout":"IPY_MODEL_63c2bc3a23ae4af98177d7b3c3da94d9"}},"fe2704f20cde47259ecd417f8c2bc7fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a65f6f7a04248be9e532c1833b4ff31","placeholder":"‚Äã","style":"IPY_MODEL_b9764f158ba7413dbe30f72b7e11b850","value":"Inference:‚Äá100%"}},"2d9fa8ffc5c54030a2c999fcf6c12afa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_455c6a257fac4af0b4ebaaa793b2f8f8","max":877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86dc2e6ebea14f0ca02b83a3cf3c4674","value":877}},"450eb8e8879d4795bb025d6d42e30f1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_262c4f3c06b54bcfaddd034ccaea19b0","placeholder":"‚Äã","style":"IPY_MODEL_d569127f0da64d57bb28ba772f4a8530","value":"‚Äá877/877‚Äá[00:28&lt;00:00,‚Äá22.49it/s]"}},"63c2bc3a23ae4af98177d7b3c3da94d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a65f6f7a04248be9e532c1833b4ff31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9764f158ba7413dbe30f72b7e11b850":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"455c6a257fac4af0b4ebaaa793b2f8f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86dc2e6ebea14f0ca02b83a3cf3c4674":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"262c4f3c06b54bcfaddd034ccaea19b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d569127f0da64d57bb28ba772f4a8530":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKsj0NdKZNiD","executionInfo":{"status":"ok","timestamp":1764721522525,"user_tz":-420,"elapsed":28791,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"710501fe-7227-4ab8-917d-fbf5a99c7f4f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ ƒê√£ c√†i ƒë·∫∑t xong th∆∞ vi·ªán!\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install -q transformers biopython kaggle\n","print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong th∆∞ vi·ªán!\")"]},{"cell_type":"code","source":["import os\n","from google.colab import files\n","\n","# Upload file kaggle.json\n","print(\"Vui l√≤ng upload file kaggle.json c·ªßa b·∫°n:\")\n","files.upload()\n","\n","# C·∫•u h√¨nh Kaggle API\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# T·∫£i d·ªØ li·ªáu cu·ªôc thi (S·∫Ω m·∫•t kho·∫£ng 1-2 ph√∫t)\n","print(\"‚è≥ ƒêang t·∫£i d·ªØ li·ªáu CAFA 6...\")\n","!kaggle competitions download -c cafa-6-protein-function-prediction\n","!unzip -q cafa-6-protein-function-prediction.zip -d /content/cafa6_data\n","print(\"‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu t·∫°i /content/cafa6_data\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"XyDuqixsZRSx","executionInfo":{"status":"ok","timestamp":1764721535513,"user_tz":-420,"elapsed":12978,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"c57a45f4-d250-4190-8a80-27dd6c30e6d2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vui l√≤ng upload file kaggle.json c·ªßa b·∫°n:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-1520262a-f7fb-4a75-8f44-54b375842ce3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-1520262a-f7fb-4a75-8f44-54b375842ce3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","‚è≥ ƒêang t·∫£i d·ªØ li·ªáu CAFA 6...\n","Downloading cafa-6-protein-function-prediction.zip to /content\n"," 73% 67.0M/91.2M [00:00<00:00, 683MB/s]\n","100% 91.2M/91.2M [00:00<00:00, 627MB/s]\n","‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu t·∫°i /content/cafa6_data\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from tqdm.auto import tqdm\n","import gc\n","import os\n","import sys\n","\n","# ============================================================================\n","# CONFIG CHO ANKH-BASE\n","# ============================================================================\n","CONFIG = {\n","    # ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu (N∆°i b·∫°n ƒë√£ g·ªôp file FINAL)\n","    'EMBED_DIR': '/content/drive/MyDrive/CAFA6_Embeddings/Final_Merged',\n","    'SAVE_DIR': '/content/drive/MyDrive/CAFA6_Results/Ankh_Base_Run',\n","    'TRAIN_TERMS': '/content/cafa6_data/Train/train_terms.tsv',\n","\n","    # Model Params\n","    'TOP_K_LABELS': 10000,\n","\n","    # Ki·∫øn tr√∫c m·∫°ng: ƒêi·ªÅu ch·ªânh cho Ankh-Base (Input 768)\n","    # Gi·∫£m xu·ªëng [1024, 512, 256] l√† ƒë·ªß m·∫°nh v√† train nhanh\n","    'HIDDEN_DIMS': [1024, 512, 256],\n","\n","    'DROPOUT_RATE': 0.25,         # Dropout chu·∫©n\n","    'EPOCHS': 40,\n","    'BATCH_SIZE': 128,            # TƒÉng batch size l√™n ƒë∆∞·ª£c n·∫øu RAM d∆∞\n","    'LEARNING_RATE': 1e-3,        # TƒÉng LR l√™n l·∫°i 1e-3 v√¨ m·∫°ng nh·ªè h∆°n d·ªÖ h·ªçc h∆°n\n","    'LABEL_SMOOTHING': 0.1,\n","\n","    # Inference Params\n","    'TEMPERATURE': 1.0,\n","    'MIN_CONFIDENCE': 0.01,\n","    'MAX_PREDS_PER_PROTEIN': 20,\n","\n","    'SEED': 42,\n","    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n","}\n","\n","# T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£\n","os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n","\n","print(\"=\"*80)\n","print(f\"üöÄ CAFA 6 - ANKH-BASE TRAINING | Device: {CONFIG['DEVICE']}\")\n","print(\"=\"*80)\n","\n","# Set seed\n","torch.manual_seed(CONFIG['SEED'])\n","np.random.seed(CONFIG['SEED'])\n","\n","# ============================================================================\n","# 1. LOAD DATA (ANKH BASE)\n","# ============================================================================\n","print(\"\\n[1/5] Loading Ankh Data (Optimized)...\")\n","\n","try:\n","    # 1. D√πng mmap_mode='r' ƒë·ªÉ KH√îNG load to√†n b·ªô file v√†o RAM ngay l·∫≠p t·ª©c\n","    # Ch·ªâ khi n√†o c·∫ßn d√πng m·ªõi ƒë·ªçc t·ª´ ƒëƒ©a\n","    print(\"   ‚è≥ Mapping Embeddings from disk...\")\n","    X_train_mmap = np.load(f\"{CONFIG['EMBED_DIR']}/ankh_train_FINAL_embeddings.npy\", mmap_mode='r')\n","    train_ids = np.load(f\"{CONFIG['EMBED_DIR']}/ankh_train_FINAL_ids.npy\")\n","\n","    # Test set kh√¥ng c·∫ßn load b√¢y gi·ªù, ƒë·ªÉ d√†nh l√∫c inference\n","    # X_test_embeds = ... (B·ªè qua ƒë·ªÉ ti·∫øt ki·ªám RAM)\n","    # test_ids = ...\n","\n","    print(f\"   ‚úì Train Embeds Mapped: {X_train_mmap.shape}\")\n","\n","except FileNotFoundError:\n","    print(\"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file FINAL!\")\n","    sys.exit(1)\n","\n","# ============================================================================\n","# 2. PROCESS LABELS (IA STRATEGY)\n","# ============================================================================\n","print(\"\\nProcessing Labels with IA Strategy...\")\n","\n","df_terms = pd.read_csv(CONFIG['TRAIN_TERMS'], sep='\\t', header=0, names=['EntryID', 'term', 'aspect'])\n","df_ia = pd.read_csv('/content/cafa6_data/IA.tsv', sep='\\t', names=['term', 'ia'])\n","ia_dict = dict(zip(df_ia['term'], df_ia['ia']))\n","\n","# T√≠nh Score = Freq * IA\n","term_counts = df_terms['term'].value_counts().reset_index()\n","term_counts.columns = ['term', 'freq']\n","term_counts['ia'] = term_counts['term'].map(ia_dict).fillna(0.0)\n","term_counts['score'] = term_counts['freq'] * term_counts['ia']\n","\n","# Ch·ªçn Top K\n","top_terms_df = term_counts.sort_values(by='score', ascending=False).head(CONFIG['TOP_K_LABELS'])\n","top_terms = top_terms_df['term'].tolist()\n","\n","print(f\"   ‚úì Selected {len(top_terms)} terms.\")\n","\n","# L·ªçc v√† t·∫°o dict\n","df_filtered = df_terms[df_terms['term'].isin(top_terms)]\n","id_to_terms = df_filtered.groupby('EntryID')['term'].apply(list).to_dict()\n","\n","# D·ªçn d·∫πp bi·∫øn trung gian ngay l·∫≠p t·ª©c\n","del df_terms, df_ia, term_counts, top_terms_df, df_filtered\n","gc.collect()\n","\n","# ============================================================================\n","# 3. PREPARE TENSORS (SPARSE & FLOAT32)\n","# ============================================================================\n","print(\"\\n[3/5] Preparing Tensors (Memory Safe)...\")\n","\n","# 1. D√πng Sparse Output ƒë·ªÉ ti·∫øt ki·ªám RAM l√∫c t·∫°o ma tr·∫≠n\n","mlb = MultiLabelBinarizer(classes=top_terms, sparse_output=True)\n","mlb.fit([top_terms])\n","\n","# 2. Transform (Ra ma tr·∫≠n th∆∞a - t·ªën r·∫•t √≠t RAM)\n","print(\"   ‚è≥ Transforming to Sparse Matrix...\")\n","y_labels_list = [id_to_terms.get(pid, []) for pid in train_ids]\n","y_train_sparse = mlb.transform(y_labels_list)\n","\n","# X√≥a list python n·∫∑ng n·ªÅ\n","del y_labels_list\n","gc.collect()\n","\n","# 3. T·∫°o Weights\n","weights_list = [ia_dict.get(t, 0.0) for t in mlb.classes_]\n","pos_weight_tensor = torch.tensor(weights_list, dtype=torch.float32).to(CONFIG['DEVICE'])\n","\n","# 4. Convert sang Dense Float32 (Ti·∫øt ki·ªám 50% RAM so v·ªõi float64 m·∫∑c ƒë·ªãnh)\n","print(\"   ‚è≥ Converting to Dense Float32...\")\n","y_train_binary = y_train_sparse.astype(np.float32).toarray()\n","del y_train_sparse\n","gc.collect()\n","\n","# 5. T·∫°o Tensor (D√πng from_numpy ƒë·ªÉ kh√¥ng copy d·ªØ li·ªáu)\n","y_train_tensor = torch.from_numpy(y_train_binary)\n","\n","# Label Smoothing (Th·ª±c hi·ªán in-place tr√™n Tensor ƒë·ªÉ kh√¥ng t·ªën RAM copy)\n","if CONFIG['LABEL_SMOOTHING'] > 0:\n","    print(\"   ‚è≥ Applying Label Smoothing in-place...\")\n","    y_train_tensor.mul_(1 - CONFIG['LABEL_SMOOTHING']).add_(CONFIG['LABEL_SMOOTHING'] / len(top_terms))\n","\n","# X√≥a b·∫£n numpy g·ªëc v√¨ gi·ªù ƒë√£ c√≥ tensor (gi·ªØ tensor th√¥i)\n","del y_train_binary\n","gc.collect()\n","\n","# 6. X·ª≠ l√Ω Input X (Load t·ª´ mmap v√†o RAM d∆∞·ªõi d·∫°ng float32)\n","print(\"   ‚è≥ Loading X into RAM as float32...\")\n","# Copy t·ª´ ƒëƒ©a v√†o RAM v√† √©p ki·ªÉu c√πng l√∫c\n","X_train_tensor = torch.tensor(X_train_mmap, dtype=torch.float32)\n","# X√≥a bi·∫øn mmap\n","del X_train_mmap\n","gc.collect()\n","\n","# ============================================================================\n","# 4. DATA SPLIT (INDICES ONLY)\n","# ============================================================================\n","# Thay v√¨ train_test_split d·ªØ li·ªáu (nh√¢n ƒë√¥i RAM), ta ch·ªâ split Index\n","print(\"   ‚è≥ Splitting Indices...\")\n","indices = np.arange(len(X_train_tensor))\n","train_idx, val_idx = train_test_split(indices, test_size=0.15, random_state=CONFIG['SEED'])\n","\n","# T·∫°o Dataset t·ª´ Subset (Kh√¥ng copy d·ªØ li·ªáu)\n","train_dataset = TensorDataset(X_train_tensor[train_idx], y_train_tensor[train_idx])\n","val_dataset = TensorDataset(X_train_tensor[val_idx], y_train_tensor[val_idx])\n","\n","# DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=False)\n","\n","print(f\"   ‚úì Ready: Train={len(train_idx)}, Val={len(val_idx)}\")\n","\n","# ============================================================================\n","# 2. MODEL ARCHITECTURE\n","# ============================================================================\n","print(\"\\n[2/5] Building MLP Model...\")\n","\n","class AnkhMLP(nn.Module):\n","    def __init__(self, input_dim, output_dim, hidden_dims, dropout):\n","        super().__init__()\n","        layers = []\n","        prev_dim = input_dim\n","\n","        for dim in hidden_dims:\n","            layers.extend([\n","                nn.Linear(prev_dim, dim),\n","                nn.BatchNorm1d(dim),\n","                nn.ReLU(),\n","                nn.Dropout(dropout)\n","            ])\n","            prev_dim = dim\n","\n","        self.encoder = nn.Sequential(*layers)\n","        self.output = nn.Linear(prev_dim, output_dim)\n","\n","    def forward(self, x):\n","        return self.output(self.encoder(x))\n","\n","model = AnkhMLP(\n","    input_dim=X_train_tensor.shape[1],\n","    output_dim=CONFIG['TOP_K_LABELS'],\n","    hidden_dims=CONFIG['HIDDEN_DIMS'],\n","    dropout=CONFIG['DROPOUT_RATE']\n",").to(CONFIG['DEVICE'])\n","\n","# ============================================================================\n","# 3. TRAINING\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(f\"TRAINING START ({CONFIG['EPOCHS']} Epochs)\")\n","print(\"=\"*80)\n","\n","criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n","optimizer = optim.AdamW(model.parameters(), lr=CONFIG['LEARNING_RATE'], weight_decay=0.01)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n","\n","best_val_loss = float('inf')\n","best_model_path = f\"{CONFIG['SAVE_DIR']}/ankh_base_best.pth\"\n","\n","for epoch in range(CONFIG['EPOCHS']):\n","    # Train\n","    model.train()\n","    train_loss = 0\n","    for X_b, y_b in train_loader:\n","        X_b, y_b = X_b.to(CONFIG['DEVICE']), y_b.to(CONFIG['DEVICE'])\n","\n","        optimizer.zero_grad()\n","        logits = model(X_b)\n","        loss = criterion(logits, y_b)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    avg_train = train_loss / len(train_loader)\n","\n","    # Val\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for X_b, y_b in val_loader:\n","            X_b, y_b = X_b.to(CONFIG['DEVICE']), y_b.to(CONFIG['DEVICE'])\n","            logits = model(X_b)\n","            loss = criterion(logits, y_b)\n","            val_loss += loss.item()\n","\n","    avg_val = val_loss / len(val_loader)\n","\n","    scheduler.step(avg_val)\n","    curr_lr = optimizer.param_groups[0]['lr']\n","\n","    print(f\"Epoch {epoch+1:02d} | Train: {avg_train:.4f} | Val: {avg_val:.4f} | LR: {curr_lr:.1e}\")\n","\n","    if avg_val < best_val_loss:\n","        best_val_loss = avg_val\n","        torch.save(model.state_dict(), best_model_path)\n","        print(\"  ‚≠ê New Best Model!\")\n","\n","print(f\"\\n‚úÖ Training Done! Best Loss: {best_val_loss:.4f}\")\n","del optimizer, scheduler, criterion, train_loader, val_loader\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xA1jFwVZRko","executionInfo":{"status":"ok","timestamp":1764723208994,"user_tz":-420,"elapsed":200921,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"dcaef0b1-de94-43a4-c8a8-31f5e936fa44"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["================================================================================\n","üöÄ CAFA 6 - ANKH-BASE TRAINING | Device: cuda\n","================================================================================\n","\n","[1/5] Loading Ankh Data (Optimized)...\n","   ‚è≥ Mapping Embeddings from disk...\n","   ‚úì Train Embeds Mapped: (82404, 768)\n","\n","Processing Labels with IA Strategy...\n","   ‚úì Selected 10000 terms.\n","\n","[3/5] Preparing Tensors (Memory Safe)...\n","   ‚è≥ Transforming to Sparse Matrix...\n","   ‚è≥ Converting to Dense Float32...\n","   ‚è≥ Applying Label Smoothing in-place...\n","   ‚è≥ Loading X into RAM as float32...\n","   ‚è≥ Splitting Indices...\n","   ‚úì Ready: Train=70043, Val=12361\n","\n","[2/5] Building MLP Model...\n","\n","================================================================================\n","TRAINING START (40 Epochs)\n","================================================================================\n","Epoch 01 | Train: 0.0248 | Val: 0.0057 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 02 | Train: 0.0057 | Val: 0.0054 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 03 | Train: 0.0055 | Val: 0.0052 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 04 | Train: 0.0052 | Val: 0.0050 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 05 | Train: 0.0050 | Val: 0.0048 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 06 | Train: 0.0048 | Val: 0.0047 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 07 | Train: 0.0046 | Val: 0.0045 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 08 | Train: 0.0044 | Val: 0.0044 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 09 | Train: 0.0042 | Val: 0.0043 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 10 | Train: 0.0041 | Val: 0.0043 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 11 | Train: 0.0040 | Val: 0.0042 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 12 | Train: 0.0039 | Val: 0.0042 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 13 | Train: 0.0038 | Val: 0.0042 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 14 | Train: 0.0037 | Val: 0.0042 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 15 | Train: 0.0037 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 16 | Train: 0.0036 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 17 | Train: 0.0035 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 18 | Train: 0.0035 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 19 | Train: 0.0035 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 20 | Train: 0.0034 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 21 | Train: 0.0034 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 22 | Train: 0.0033 | Val: 0.0041 | LR: 1.0e-03\n","  ‚≠ê New Best Model!\n","Epoch 23 | Train: 0.0033 | Val: 0.0041 | LR: 1.0e-03\n","Epoch 24 | Train: 0.0033 | Val: 0.0041 | LR: 1.0e-03\n","Epoch 25 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-03\n","Epoch 26 | Train: 0.0032 | Val: 0.0041 | LR: 5.0e-04\n","Epoch 27 | Train: 0.0031 | Val: 0.0041 | LR: 5.0e-04\n","  ‚≠ê New Best Model!\n","Epoch 28 | Train: 0.0030 | Val: 0.0041 | LR: 5.0e-04\n","  ‚≠ê New Best Model!\n","Epoch 29 | Train: 0.0030 | Val: 0.0041 | LR: 5.0e-04\n","Epoch 30 | Train: 0.0030 | Val: 0.0041 | LR: 5.0e-04\n","Epoch 31 | Train: 0.0030 | Val: 0.0041 | LR: 2.5e-04\n","Epoch 32 | Train: 0.0029 | Val: 0.0041 | LR: 2.5e-04\n","Epoch 33 | Train: 0.0029 | Val: 0.0041 | LR: 2.5e-04\n","Epoch 34 | Train: 0.0029 | Val: 0.0041 | LR: 2.5e-04\n","Epoch 35 | Train: 0.0029 | Val: 0.0041 | LR: 1.3e-04\n","Epoch 36 | Train: 0.0028 | Val: 0.0041 | LR: 1.3e-04\n","Epoch 37 | Train: 0.0028 | Val: 0.0041 | LR: 1.3e-04\n","Epoch 38 | Train: 0.0028 | Val: 0.0041 | LR: 1.3e-04\n","Epoch 39 | Train: 0.0028 | Val: 0.0041 | LR: 6.3e-05\n","Epoch 40 | Train: 0.0028 | Val: 0.0041 | LR: 6.3e-05\n","\n","‚úÖ Training Done! Best Loss: 0.0041\n"]}]},{"cell_type":"code","source":["X_test_embeds = np.load(f\"{CONFIG['EMBED_DIR']}/ankh_test_FINAL_embeddings.npy\")\n","\n","test_ids = np.load(f\"{CONFIG['EMBED_DIR']}/ankh_test_FINAL_ids.npy\")\n","\n","# ============================================================================\n","# 4. PREDICTION & SUBMISSION\n","# ============================================================================\n","print(\"\\n[4/5] Predicting & Creating Submission...\")\n","\n","model.load_state_dict(torch.load(best_model_path))\n","model.eval()\n","\n","# Dataset cho Test\n","test_dataset = TensorDataset(torch.FloatTensor(X_test_embeds))\n","test_loader = DataLoader(test_dataset, batch_size=CONFIG['BATCH_SIZE']*2, shuffle=False, num_workers=2)\n","\n","submission_path = f\"{CONFIG['SAVE_DIR']}/submission.tsv\"\n","n_predictions = 0\n","\n","with open(submission_path, 'w') as f:\n","    current_idx = 0\n","    with torch.no_grad():\n","        for (X_b,) in tqdm(test_loader, desc=\"Inference\"):\n","            X_b = X_b.to(CONFIG['DEVICE'])\n","            logits = model(X_b)\n","            probs_batch = torch.sigmoid(logits / CONFIG['TEMPERATURE']).cpu().numpy()\n","\n","            # Mapping IDs\n","            batch_len = len(probs_batch)\n","            ids_batch = test_ids[current_idx : current_idx + batch_len]\n","            current_idx += batch_len\n","\n","            for i, pid in enumerate(ids_batch):\n","                probs = probs_batch[i]\n","\n","                # Logic ch·ªçn Top K\n","                top_k = min(len(probs), CONFIG['MAX_PREDS_PER_PROTEIN'])\n","                ind = np.argpartition(probs, -top_k)[-top_k:]\n","                ind = ind[np.argsort(probs[ind])][::-1]\n","\n","                for idx in ind:\n","                    score = probs[idx]\n","                    if score > CONFIG['MIN_CONFIDENCE']:\n","                        f.write(f\"{pid}\\t{top_terms[idx]}\\t{score:.3f}\\n\")\n","                        n_predictions += 1\n","\n","            del probs_batch, X_b, logits\n","\n","print(f\"\\n‚úÖ DONE! Predictions: {n_predictions:,}\")\n","print(f\"üëâ Submission: {submission_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["bb77557fa7644c038cf75f85339e40a8","fe2704f20cde47259ecd417f8c2bc7fe","2d9fa8ffc5c54030a2c999fcf6c12afa","450eb8e8879d4795bb025d6d42e30f1f","63c2bc3a23ae4af98177d7b3c3da94d9","7a65f6f7a04248be9e532c1833b4ff31","b9764f158ba7413dbe30f72b7e11b850","455c6a257fac4af0b4ebaaa793b2f8f8","86dc2e6ebea14f0ca02b83a3cf3c4674","262c4f3c06b54bcfaddd034ccaea19b0","d569127f0da64d57bb28ba772f4a8530"]},"id":"0K4YHAQHphN9","executionInfo":{"status":"ok","timestamp":1764723241359,"user_tz":-420,"elapsed":32354,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"59d74259-aaa9-43db-fcdc-42b089f245f1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","[4/5] Predicting & Creating Submission...\n"]},{"output_type":"display_data","data":{"text/plain":["Inference:   0%|          | 0/877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb77557fa7644c038cf75f85339e40a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ DONE! Predictions: 4,421,549\n","üëâ Submission: /content/drive/MyDrive/CAFA6_Results/Ankh_Base_Run/submission.tsv\n"]}]},{"cell_type":"code","source":["# Ch·∫°y l·ªánh n√†y trong m·ªôt cell m·ªõi\n","!kaggle competitions submit \\\n","    -c cafa-6-protein-function-prediction \\\n","    -f /content/drive/MyDrive/CAFA6_Results/Ankh_Base_Run/submission.tsv \\\n","    -m \"ankh top-k=20 top-k-label=10k\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfKYzKqwei36","executionInfo":{"status":"ok","timestamp":1764723281292,"user_tz":-420,"elapsed":4405,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"5c5adc20-5fdf-4a5b-cb70-73e9a2ec9b62"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 102M/102M [00:02<00:00, 50.5MB/s] \n","Successfully submitted to CAFA 6 Protein Function Prediction"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jF3DPnqLeyAL"},"execution_count":null,"outputs":[]}]}