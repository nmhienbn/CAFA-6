{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nRSmLc4X9iAvAk3FMbwr65P3rO3FPQfr","timestamp":1765015080264},{"file_id":"1ugPorXq9h0mFcNMLWjHrzRrqVzl6Giki","timestamp":1764841075937},{"file_id":"1jSzyY6ZS3JVm9PyP7duVHraeAOkIZCmt","timestamp":1764839549669},{"file_id":"1UxqF75DnqW2s5fqUcWxc_wuYzbfKBEas","timestamp":1764820130596},{"file_id":"18JK8_wNZ-YmK9L0IpgsFVlfz4WepTAaI","timestamp":1764732925834},{"file_id":"1aTJ8MIZ0uPzAFCjHOyUVoHPO_-spwG_X","timestamp":1764643689455},{"file_id":"1RWuBvKFQQQeTmcicgX1HGtINRBe7HF5_","timestamp":1764406804022}],"gpuType":"T4","authorship_tag":"ABX9TyMs+VijFIu29NGJq9NPnZly"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4883ba290fc54b25926232ede5a1c93a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46ee4642daf44d17ab67ec95dd49c9eb","IPY_MODEL_a0b2fb2ba01c4779922c0dd615c404d0","IPY_MODEL_c55116d2846840279a45fa1b0bd7f8e8"],"layout":"IPY_MODEL_125104fd769d4651a91e3bf32c84d0f8"}},"46ee4642daf44d17ab67ec95dd49c9eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3b2e80249d41ae9467f2b70bc85abe","placeholder":"‚Äã","style":"IPY_MODEL_d9ae3e2c33264d93b8da69237faccc92","value":"Inference:‚Äá100%"}},"a0b2fb2ba01c4779922c0dd615c404d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d98b05e9a84d4621948533e1230b8cdf","max":877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_38b98e0d3d354995900fb12bce96d6ac","value":877}},"c55116d2846840279a45fa1b0bd7f8e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9212ff9c1034d9db947418df6b1cffe","placeholder":"‚Äã","style":"IPY_MODEL_4680b4b20c394bffacbb2aa5cb573b8e","value":"‚Äá877/877‚Äá[00:58&lt;00:00,‚Äá23.13it/s]"}},"125104fd769d4651a91e3bf32c84d0f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3b2e80249d41ae9467f2b70bc85abe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ae3e2c33264d93b8da69237faccc92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98b05e9a84d4621948533e1230b8cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b98e0d3d354995900fb12bce96d6ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9212ff9c1034d9db947418df6b1cffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4680b4b20c394bffacbb2aa5cb573b8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UKsj0NdKZNiD","executionInfo":{"status":"ok","timestamp":1765017724758,"user_tz":-420,"elapsed":26515,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"ed906605-6d77-495d-a2e6-b5f1b9f79345"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ ƒê√£ c√†i ƒë·∫∑t xong th∆∞ vi·ªán!\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install -q transformers biopython kaggle\n","print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong th∆∞ vi·ªán!\")"]},{"cell_type":"code","source":["import os\n","from google.colab import files\n","\n","# Upload file kaggle.json\n","print(\"Vui l√≤ng upload file kaggle.json c·ªßa b·∫°n:\")\n","files.upload()\n","\n","# C·∫•u h√¨nh Kaggle API\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# T·∫£i d·ªØ li·ªáu cu·ªôc thi (S·∫Ω m·∫•t kho·∫£ng 1-2 ph√∫t)\n","print(\"‚è≥ ƒêang t·∫£i d·ªØ li·ªáu CAFA 6...\")\n","!kaggle competitions download -c cafa-6-protein-function-prediction\n","!unzip -q cafa-6-protein-function-prediction.zip -d /content/cafa6_data\n","print(\"‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu t·∫°i /content/cafa6_data\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"XyDuqixsZRSx","executionInfo":{"status":"ok","timestamp":1765017737017,"user_tz":-420,"elapsed":12256,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"d7cd3ff0-1805-4d7a-819b-2f4d0503c31f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vui l√≤ng upload file kaggle.json c·ªßa b·∫°n:\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-666d6b67-d843-41d2-b7d7-12c003ce00b1\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-666d6b67-d843-41d2-b7d7-12c003ce00b1\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","‚è≥ ƒêang t·∫£i d·ªØ li·ªáu CAFA 6...\n","Downloading cafa-6-protein-function-prediction.zip to /content\n","  0% 0.00/91.2M [00:00<?, ?B/s]\n","100% 91.2M/91.2M [00:00<00:00, 1.12GB/s]\n","‚úÖ ƒê√£ t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu t·∫°i /content/cafa6_data\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","import gc\n","import os\n","import sys\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import KFold\n","\n","# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","CONFIG = {\n","    'EMBEDDINGS': {\n","        'ankh': {\n","            'train': '/content/drive/MyDrive/CAFA6_Embeddings/Final_Merged/ankh_train_FINAL_embeddings.npy',\n","            'test':  '/content/drive/MyDrive/CAFA6_Embeddings/Final_Merged/ankh_test_FINAL_embeddings.npy',\n","        },\n","        'esm': {\n","            'train': '/content/drive/MyDrive/CAFA6_Embeddings/ESM2_Aligned_Ankh/esm2_train_FINAL_embeddings.npy',\n","            'test':  '/content/drive/MyDrive/CAFA6_Embeddings/ESM2_Aligned_Ankh/esm2_test_FINAL_embeddings.npy',\n","        },\n","        'prot_t5': {\n","            'train': '/content/drive/MyDrive/CAFA6_Embeddings/Prot_T5_Aligned/protT5_xl_train_FINAL_embeddings.npy',\n","            'test':  '/content/drive/MyDrive/CAFA6_Embeddings/Prot_T5_Aligned/protT5_xl_test_FINAL_embeddings.npy',\n","        },\n","        # 'protBERT': {\n","        #     'train': '/content/drive/MyDrive/CAFA6_Embeddings/protBERT_Aligned/protBERT_train_FINAL_embeddings.npy',\n","        #     'test':  '/content/drive/MyDrive/CAFA6_Embeddings/protBERT_Aligned/protBERT_test_FINAL_embeddings.npy',\n","        # },\n","    },\n","\n","    'TRAIN_ID_PATH': '/content/drive/MyDrive/CAFA6_Embeddings/Final_Merged/ankh_train_FINAL_ids.npy',\n","    'TEST_ID_PATH':  '/content/drive/MyDrive/CAFA6_Embeddings/Final_Merged/ankh_test_FINAL_ids.npy',\n","\n","    'SAVE_DIR': '/content/drive/MyDrive/CAFA6_Results/prott5_esm2_ankh_k_fold_Run',\n","    'TRAIN_TERMS': '/content/cafa6_data/Train/train_terms.tsv',\n","    'IA_FILE': '/content/cafa6_data/IA.tsv',\n","    'TEST_FASTA': '/content/cafa6_data/Test/testsuperset.fasta',\n","\n","    # Model Params\n","    'TOP_K_LABELS': 10000, # Gi·ªØ m·ª©c n√†y ƒë·ªÉ model h·ªçc t·ªët\n","    # 'MIN_FREQ': 3,\n","\n","    # Input s·∫Ω l√† 768 (Ankh) + 1280 (ESM) = 2048\n","    'ENCODER_LAYERS': [2048, 1024, 512],\n","\n","    'DROPOUT_RATE': 0.4, # TƒÉng dropout v√¨ input l·ªõn\n","    'N_FOLDS': 5,\n","    'EPOCHS': 50,\n","    'BATCH_SIZE': 128,\n","    'LEARNING_RATE': 2e-4, # Gi·∫£m LR m·ªôt ch√∫t cho ·ªïn ƒë·ªãnh\n","    'LABEL_SMOOTHING': 0.1,\n","\n","    # Inference Params (Chu·∫©n 0.27 ƒëi·ªÉm)\n","    'MIN_CONFIDENCE': 0.01,\n","    'MAX_PREDS_PER_PROTEIN': 20,\n","\n","    'SEED': 42,\n","    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu'\n","}\n","\n","os.makedirs(CONFIG['SAVE_DIR'], exist_ok=True)\n","print(f\"üöÄ CAFA 6 - DUAL MODEL (ANKH + ESM) | Device: {CONFIG['DEVICE']}\")\n","\n","torch.manual_seed(CONFIG['SEED'])\n","np.random.seed(CONFIG['SEED'])\n","\n","# ============================================================================\n","# 1. MEMORY-SAFE DATASET (CH√åA KH√ìA ƒê·ªÇ KH√îNG TR√ÄN RAM)\n","# ============================================================================\n","class MultiSourceDataset(Dataset):\n","    def __init__(self, embedding_paths_dict, y_tensor=None, indices=None):\n","        self.mmaps = {}\n","        self.keys = list(embedding_paths_dict.keys())\n","\n","        # Load mmap\n","        for name, path in embedding_paths_dict.items():\n","            self.mmaps[name] = np.load(path, mmap_mode='r')\n","\n","        # Base length\n","        first_key = self.keys[0]\n","        self.total_len = len(self.mmaps[first_key])\n","\n","        self.indices = indices if indices is not None else np.arange(self.total_len)\n","        self.y = y_tensor\n","\n","    def __len__(self):\n","        return len(self.indices)\n","\n","    def __getitem__(self, idx):\n","        real_idx = self.indices[idx]\n","\n","        inputs = []\n","        # Load t·ª´ng vector -> List of Tensors\n","        for key in self.keys:\n","            vec = torch.from_numpy(self.mmaps[key][real_idx].copy()).float()\n","            inputs.append(vec)\n","\n","        if self.y is not None:\n","            return inputs, self.y[real_idx]\n","        return (inputs,)\n","\n","# ============================================================================\n","# 2. LOAD DATA & PROCESS LABELS\n","# ============================================================================\n","print(\"\\n[1/5] Checking Files...\")\n","train_ids = np.load(CONFIG['TRAIN_ID_PATH'])\n","print(f\"   ‚úì Train IDs: {len(train_ids)}\")\n","\n","print(\"\\n[2/5] Processing Labels (IA Strategy)...\")\n","# 1. Load Terms & IA\n","df_terms = pd.read_csv(CONFIG['TRAIN_TERMS'], sep='\\t', header=0, names=['EntryID', 'term', 'aspect'])\n","df_ia = pd.read_csv(CONFIG['IA_FILE'], sep='\\t', names=['term', 'ia'])\n","ia_dict = dict(zip(df_ia['term'], df_ia['ia']))\n","\n","# 2. T√≠nh Score\n","term_counts = df_terms['term'].value_counts().reset_index()\n","term_counts.columns = ['term', 'freq']\n","\n","# print(f\"   Original terms count: {len(term_counts)}\")\n","# term_counts = term_counts[term_counts['freq'] >= CONFIG['MIN_FREQ']]\n","# print(f\"   -> After filtering (Freq >= {CONFIG['MIN_FREQ']}): {len(term_counts)} terms\")\n","\n","term_counts['ia'] = term_counts['term'].map(ia_dict).fillna(0.0)\n","term_counts['score'] = term_counts['freq'] * term_counts['ia']\n","\n","# 3. Ch·ªçn Top K\n","top_terms_df = term_counts.sort_values(by='score', ascending=False).head(CONFIG['TOP_K_LABELS'])\n","top_terms = top_terms_df['term'].tolist()\n","print(f\"   ‚úì Selected {len(top_terms)} terms.\")\n","\n","# 4. Map ID -> Terms\n","df_filtered = df_terms[df_terms['term'].isin(top_terms)]\n","id_to_terms = df_filtered.groupby('EntryID')['term'].apply(list).to_dict()\n","\n","# D·ªçn d·∫πp\n","del df_terms, df_filtered, df_ia, term_counts, top_terms_df\n","gc.collect()\n","\n","# ============================================================================\n","# 3. PREPARE LABELS (RAM OPTIMIZED)\n","# ============================================================================\n","print(\"\\n[3/5] Preparing Labels (Sparse Mode)...\")\n","\n","# 1. Sparse MLB\n","mlb = MultiLabelBinarizer(classes=top_terms, sparse_output=True)\n","mlb.fit([top_terms])\n","\n","# 2. Transform -> Sparse Matrix\n","y_labels_list = [id_to_terms.get(pid, []) for pid in train_ids]\n","y_train_sparse = mlb.transform(y_labels_list)\n","del y_labels_list, train_ids # X√≥a ID list kh√¥ng d√πng n·ªØa\n","gc.collect()\n","\n","# 3. Weights (Optional)\n","# N·∫øu d√πng IA weight th√¨ gi·ªØ, n·∫øu mu·ªën model t·ª± h·ªçc th√¨ comment d√≤ng n√†y v√† b·ªè pos_weight trong Loss\n","weights_list = [ia_dict.get(t, 0.0) for t in mlb.classes_]\n","pos_weight_tensor = torch.tensor(weights_list, dtype=torch.float32).to(CONFIG['DEVICE'])\n","\n","# 4. Convert to Dense Float32 & Label Smoothing\n","print(\"   ‚è≥ Converting Labels to Tensor...\")\n","# Convert t·ª´ng ph·∫ßn nh·ªè ho·∫∑c convert h·∫øt n·∫øu RAM > 12GB (v·ªõi 80k row x 10k col float32 ~ 3.2GB -> ·ªîn)\n","y_train_binary = y_train_sparse.astype(np.float32).toarray()\n","y_train_tensor = torch.from_numpy(y_train_binary)\n","\n","if CONFIG['LABEL_SMOOTHING'] > 0:\n","    y_train_tensor.mul_(1 - CONFIG['LABEL_SMOOTHING']).add_(CONFIG['LABEL_SMOOTHING'] / len(top_terms))\n","\n","del y_train_sparse, y_train_binary\n","gc.collect()\n","\n","# ============================================================================\n","# 4. CREATE DATA LOADERS\n","# ============================================================================\n","print(\"\\n[4/5] Creating DataLoaders...\")\n","\n","train_paths = {k: v['train'] for k, v in CONFIG['EMBEDDINGS'].items()}\n","\n","temp_ds = MultiSourceDataset(train_paths, y_train_tensor)\n","sample_inputs, _ = temp_ds[0]\n","INPUT_DIMS_LIST = [x.shape[0] for x in sample_inputs]\n","print(f\"   ‚úì Input Dims Detected: {INPUT_DIMS_LIST}\")\n","del temp_ds\n","\n","# ============================================================================\n","# 5. MODEL & TRAINING\n","# ============================================================================\n","print(\"\\n[5/5] Building Model...\")\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(self, in_dim, layers_config, dropout):\n","        super().__init__()\n","        layers = []\n","\n","        # 1. LAYER NORM ƒê·∫¶U V√ÄO (B·∫ÆT BU·ªòC)\n","        # ƒê·ªÉ c√¢n b·∫±ng '√¢m l∆∞·ª£ng' gi·ªØa ESM (h√©t to) v√† Ankh (n√≥i nh·ªè)\n","        layers.append(nn.LayerNorm(in_dim))\n","\n","        prev_dim = in_dim\n","        for i, dim in enumerate(layers_config):\n","            layers.extend([\n","                nn.Linear(prev_dim, dim),\n","                nn.BatchNorm1d(dim), # ·ªîn ƒë·ªãnh training\n","                nn.GELU(),           # Hi·ªán ƒë·∫°i h∆°n ReLU\n","                nn.Dropout(dropout)\n","            ])\n","            prev_dim = dim\n","\n","        self.net = nn.Sequential(*layers)\n","        self.out_dim = prev_dim\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","# Module l·ªçc nhi·ªÖu (Attention)\n","class SEBlock(nn.Module):\n","    \"\"\"Squeeze-and-Excitation Block ƒë·ªÉ l·ªçc nhi·ªÖu sau khi g·ªôp\"\"\"\n","    def __init__(self, in_dim, reduction=4):\n","        super().__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(in_dim, in_dim // reduction, bias=False),\n","            nn.ReLU(),\n","            nn.Linear(in_dim // reduction, in_dim, bias=False),\n","            nn.Sigmoid() # T·∫°o ra mask t·ª´ 0 ƒë·∫øn 1\n","        )\n","\n","    def forward(self, x):\n","        # x shape: [Batch, Dim]\n","        # Attention weight: [Batch, Dim]\n","        w = self.fc(x)\n","        # Nh√¢n tr·ªçng s·ªë v√†o x: C√°i n√†o quan tr·ªçng th√¨ gi·ªØ, r√°c th√¨ nh√¢n v·ªõi 0\n","        return x * w\n","\n","class MultiModalNet(nn.Module):\n","    def __init__(self, input_dims_list, encoder_layers, dropout, num_classes):\n","        super().__init__()\n","\n","        self.encoders = nn.ModuleList()\n","        self.fusion_input_dim = 0\n","\n","        print(\"\\nüèóÔ∏è Building Advanced Architecture:\")\n","\n","        # 1. X√¢y d·ª±ng c√°c nh√°nh Encoder\n","        for i, in_dim in enumerate(input_dims_list):\n","            print(f\"   ‚û§ Branch {i+1}: Input {in_dim} -> Output {encoder_layers[-1]}\")\n","            enc = EncoderBlock(in_dim, encoder_layers, dropout)\n","            self.encoders.append(enc)\n","            self.fusion_input_dim += enc.out_dim\n","\n","        print(f\"   ‚û§ Fusion Dim: {self.fusion_input_dim}\")\n","\n","        # 2. SE-Block (B·ªô l·ªçc th√¥ng minh)\n","        self.attention_filter = SEBlock(self.fusion_input_dim)\n","\n","        # 3. Layer t·ªïng h·ª£p cu·ªëi c√πng\n","        self.head = nn.Sequential(\n","            nn.BatchNorm1d(self.fusion_input_dim),\n","            nn.Linear(self.fusion_input_dim, 512),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","\n","            # Th√™m m·ªôt l·ªõp n·ªØa ƒë·ªÉ tƒÉng kh·∫£ nƒÉng h·ªçc\n","            nn.Linear(512, 512),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, inputs_list):\n","        features = []\n","        # ƒêi qua t·ª´ng nh√°nh\n","        for i, encoder in enumerate(self.encoders):\n","            feat = encoder(inputs_list[i])\n","            features.append(feat)\n","\n","        # G·ªôp l·∫°i (Concatenate)\n","        combined = torch.cat(features, dim=1)\n","\n","        # L·ªåC NHI·ªÑU (ƒêi·ªÉm kh√°c bi·ªát l·ªõn nh·∫•t)\n","        # M·∫°ng s·∫Ω t·ª± h·ªçc c√°ch \"t·∫Øt ti·∫øng\" c√°c ƒë·∫∑c tr∆∞ng r√°c t·ª´ ProtT5 n·∫øu n√≥ th·∫•y kh√¥ng c·∫ßn thi·∫øt\n","        refined = self.attention_filter(combined)\n","\n","        return self.head(refined)\n","\n","kf = KFold(n_splits=CONFIG['N_FOLDS'], shuffle=True, random_state=CONFIG['SEED'])\n","all_indices = np.arange(len(y_train_tensor))\n","\n","# ============================================================================\n","# 6. K-FOLD TRAINING LOOP\n","# ============================================================================\n","print(f\"\\nüöÄ STARTING {CONFIG['N_FOLDS']}-FOLD TRAINING...\")\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(all_indices)):\n","    print(f\"\\n\" + \"=\"*40)\n","    print(f\"üîÑ FOLD {fold+1}/{CONFIG['N_FOLDS']}\")\n","    print(\"=\"*40)\n","\n","    # --- A. T·∫°o DataLoaders cho Fold hi·ªán t·∫°i ---\n","    train_ds = MultiSourceDataset(train_paths, y_train_tensor, indices=train_idx)\n","    val_ds   = MultiSourceDataset(train_paths, y_train_tensor, indices=val_idx)\n","\n","    train_loader = DataLoader(train_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=True, num_workers=2)\n","    val_loader   = DataLoader(val_ds, batch_size=CONFIG['BATCH_SIZE'], shuffle=False, num_workers=2)\n","\n","    # --- B. Kh·ªüi t·∫°o Model M·ªõi (Reset Weights) ---\n","    # Ph·∫£i t·∫°o m·ªõi ho√†n to√†n ƒë·ªÉ kh√¥ng d√≠nh d√°ng ƒë·∫øn fold tr∆∞·ªõc\n","    model = MultiModalNet(\n","        input_dims_list = INPUT_DIMS_LIST,\n","        encoder_layers  = CONFIG['ENCODER_LAYERS'],\n","        dropout         = CONFIG['DROPOUT_RATE'],\n","        num_classes     = len(top_terms)\n","    ).to(CONFIG['DEVICE'])\n","\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n","    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['LEARNING_RATE'], weight_decay=0.01)\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n","\n","    # --- C. Training Loop cho Fold n√†y ---\n","    best_val_loss = float('inf')\n","    fold_save_path = f\"{CONFIG['SAVE_DIR']}/model_fold_{fold+1}.pth\"\n","\n","    for epoch in range(CONFIG['EPOCHS']):\n","        model.train()\n","        train_loss = 0\n","\n","        for X_b, y_b in train_loader:\n","            X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n","            y_b = y_b.to(CONFIG['DEVICE'])\n","\n","            optimizer.zero_grad()\n","            logits = model(X_b)\n","            loss = criterion(logits, y_b)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            train_loss += loss.item()\n","\n","        avg_train = train_loss / len(train_loader)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        with torch.no_grad():\n","            for X_b, y_b in val_loader:\n","                X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n","                y_b = y_b.to(CONFIG['DEVICE'])\n","                val_loss += criterion(model(X_b), y_b).item()\n","\n","        avg_val = val_loss / len(val_loader)\n","        scheduler.step(avg_val)\n","\n","        print(f\"   Epoch {epoch+1:02d} | Train: {avg_train:.4f} | Val: {avg_val:.4f} | LR: {optimizer.param_groups[0]['lr']:.1e}\")\n","\n","        if avg_val < best_val_loss:\n","            best_val_loss = avg_val\n","            torch.save(model.state_dict(), fold_save_path)\n","            print(f\"     ‚≠ê Best Fold {fold+1} Model Saved! ({avg_val:.4f})\")\n","\n","    # D·ªçn d·∫πp RAM sau m·ªói Fold ƒë·ªÉ tr√°nh OOM\n","    del model, optimizer, scheduler, train_loader, val_loader, train_ds, val_ds\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","print(\"\\n‚úÖ K-FOLD TRAINING COMPLETED!\")\n","\n","# # ============================================================================\n","# # 6. INFERENCE (STREAMING)\n","# # ============================================================================\n","# print(\"\\nüîÆ PREDICTING...\")\n","\n","# model.load_state_dict(torch.load(best_model_path))\n","# model.eval()\n","\n","# # Load Test IDs & Paths\n","# test_paths = {k: v['test'] for k, v in CONFIG['EMBEDDINGS'].items()}\n","# test_ids = np.load(CONFIG['TEST_ID_PATH'])\n","\n","# # Test Dataset (Dual Memmap)\n","# test_dataset = MultiSourceDataset(test_paths)\n","# test_loader = DataLoader(test_dataset, batch_size=CONFIG['BATCH_SIZE']*2, shuffle=False, num_workers=2)\n","\n","# submission_path = f\"{CONFIG['SAVE_DIR']}/submission.tsv\"\n","# n_predictions = 0\n","\n","# with open(submission_path, 'w') as f:\n","#     current_idx = 0\n","#     with torch.no_grad():\n","#         for (X_b,) in tqdm(test_loader, desc=\"Inference\"):\n","#             X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n","#             logits = model(X_b)\n","#             probs_batch = torch.sigmoid(logits).cpu().numpy()\n","\n","#             ids_batch = test_ids[current_idx : current_idx + len(probs_batch)]\n","#             current_idx += len(probs_batch)\n","\n","#             for i, pid in enumerate(ids_batch):\n","#                 probs = probs_batch[i]\n","\n","#                 # TOP-K C·ª®NG (Chi·∫øn thu·∫≠t 0.27 ƒëi·ªÉm)\n","#                 top_k = CONFIG['MAX_PREDS_PER_PROTEIN']\n","#                 ind = np.argpartition(probs, -top_k)[-top_k:]\n","#                 ind = ind[np.argsort(probs[ind])][::-1]\n","\n","#                 for idx in ind:\n","#                     score = probs[idx]\n","#                     if score > CONFIG['MIN_CONFIDENCE']:\n","#                         f.write(f\"{pid}\\t{top_terms[idx]}\\t{score:.3f}\\n\")\n","#                         n_predictions += 1\n","\n","#             del probs_batch, X_b, logits\n","\n","# print(f\"\\n‚úÖ DONE! File: {submission_path}\")\n","# print(f\"\\n‚úÖ DONE! Predictions: {n_predictions:,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xA1jFwVZRko","outputId":"f7aeb892-1f31-464a-b5ac-1949cd8f6111","executionInfo":{"status":"ok","timestamp":1765022015953,"user_tz":-420,"elapsed":4278934,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ CAFA 6 - DUAL MODEL (ANKH + ESM) | Device: cuda\n","\n","[1/5] Checking Files...\n","   ‚úì Train IDs: 82404\n","\n","[2/5] Processing Labels (IA Strategy)...\n","   ‚úì Selected 10000 terms.\n","\n","[3/5] Preparing Labels (Sparse Mode)...\n","   ‚è≥ Converting Labels to Tensor...\n","\n","[4/5] Creating DataLoaders...\n","   ‚úì Input Dims Detected: [768, 1280, 1024]\n","\n","[5/5] Building Model...\n","\n","üöÄ STARTING 5-FOLD TRAINING...\n","\n","========================================\n","üîÑ FOLD 1/5\n","========================================\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   Epoch 01 | Train: 0.0375 | Val: 0.0057 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0057)\n","   Epoch 02 | Train: 0.0061 | Val: 0.0056 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0056)\n","   Epoch 03 | Train: 0.0059 | Val: 0.0054 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0054)\n","   Epoch 04 | Train: 0.0057 | Val: 0.0053 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0053)\n","   Epoch 05 | Train: 0.0055 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0052)\n","   Epoch 06 | Train: 0.0054 | Val: 0.0051 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0051)\n","   Epoch 07 | Train: 0.0052 | Val: 0.0050 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0050)\n","   Epoch 08 | Train: 0.0051 | Val: 0.0048 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0048)\n","   Epoch 09 | Train: 0.0050 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0047)\n","   Epoch 10 | Train: 0.0049 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0046)\n","   Epoch 11 | Train: 0.0047 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0046)\n","   Epoch 12 | Train: 0.0047 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0045)\n","   Epoch 13 | Train: 0.0046 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0045)\n","   Epoch 14 | Train: 0.0045 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0044)\n","   Epoch 15 | Train: 0.0044 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0044)\n","   Epoch 16 | Train: 0.0043 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0043)\n","   Epoch 17 | Train: 0.0043 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0043)\n","   Epoch 18 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0043)\n","   Epoch 19 | Train: 0.0041 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0043)\n","   Epoch 20 | Train: 0.0041 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0042)\n","   Epoch 21 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0042)\n","   Epoch 22 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0042)\n","   Epoch 23 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0042)\n","   Epoch 24 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 25 | Train: 0.0038 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 26 | Train: 0.0038 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 27 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 28 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 29 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 30 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 31 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 32 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 33 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 34 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 35 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 36 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0041)\n","   Epoch 37 | Train: 0.0035 | Val: 0.0040 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0040)\n","   Epoch 38 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 39 | Train: 0.0034 | Val: 0.0040 | LR: 2.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0040)\n","   Epoch 40 | Train: 0.0034 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 41 | Train: 0.0033 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 42 | Train: 0.0033 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 43 | Train: 0.0033 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 44 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 45 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","     ‚≠ê Best Fold 1 Model Saved! (0.0040)\n","   Epoch 46 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 47 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 48 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 49 | Train: 0.0031 | Val: 0.0040 | LR: 5.0e-05\n","   Epoch 50 | Train: 0.0031 | Val: 0.0040 | LR: 5.0e-05\n","\n","========================================\n","üîÑ FOLD 2/5\n","========================================\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   Epoch 01 | Train: 0.0378 | Val: 0.0058 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0058)\n","   Epoch 02 | Train: 0.0061 | Val: 0.0056 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0056)\n","   Epoch 03 | Train: 0.0059 | Val: 0.0055 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0055)\n","   Epoch 04 | Train: 0.0057 | Val: 0.0053 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0053)\n","   Epoch 05 | Train: 0.0055 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0052)\n","   Epoch 06 | Train: 0.0054 | Val: 0.0051 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0051)\n","   Epoch 07 | Train: 0.0052 | Val: 0.0049 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0049)\n","   Epoch 08 | Train: 0.0051 | Val: 0.0049 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0049)\n","   Epoch 09 | Train: 0.0050 | Val: 0.0048 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0048)\n","   Epoch 10 | Train: 0.0048 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0047)\n","   Epoch 11 | Train: 0.0048 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0046)\n","   Epoch 12 | Train: 0.0047 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0046)\n","   Epoch 13 | Train: 0.0046 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0045)\n","   Epoch 14 | Train: 0.0045 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0045)\n","   Epoch 15 | Train: 0.0044 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0044)\n","   Epoch 16 | Train: 0.0043 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0044)\n","   Epoch 17 | Train: 0.0043 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0043)\n","   Epoch 18 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0043)\n","   Epoch 19 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0043)\n","   Epoch 20 | Train: 0.0041 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0042)\n","   Epoch 21 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0042)\n","   Epoch 22 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0042)\n","   Epoch 23 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0042)\n","   Epoch 24 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0042)\n","   Epoch 25 | Train: 0.0039 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 26 | Train: 0.0038 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 27 | Train: 0.0038 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 28 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 29 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 30 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 31 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 32 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 33 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0041)\n","   Epoch 34 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 35 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 36 | Train: 0.0035 | Val: 0.0040 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0040)\n","   Epoch 37 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 38 | Train: 0.0034 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 39 | Train: 0.0034 | Val: 0.0040 | LR: 2.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0040)\n","   Epoch 40 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 41 | Train: 0.0034 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 42 | Train: 0.0033 | Val: 0.0040 | LR: 2.0e-04\n","   Epoch 43 | Train: 0.0033 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 44 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0040)\n","   Epoch 45 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0040)\n","   Epoch 46 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","     ‚≠ê Best Fold 2 Model Saved! (0.0040)\n","   Epoch 47 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 48 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 49 | Train: 0.0032 | Val: 0.0040 | LR: 1.0e-04\n","   Epoch 50 | Train: 0.0031 | Val: 0.0040 | LR: 5.0e-05\n","\n","========================================\n","üîÑ FOLD 3/5\n","========================================\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   Epoch 01 | Train: 0.0373 | Val: 0.0058 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0058)\n","   Epoch 02 | Train: 0.0061 | Val: 0.0056 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0056)\n","   Epoch 03 | Train: 0.0059 | Val: 0.0054 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0054)\n","   Epoch 04 | Train: 0.0057 | Val: 0.0054 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0054)\n","   Epoch 05 | Train: 0.0055 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0052)\n","   Epoch 06 | Train: 0.0053 | Val: 0.0051 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0051)\n","   Epoch 07 | Train: 0.0052 | Val: 0.0050 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0050)\n","   Epoch 08 | Train: 0.0051 | Val: 0.0049 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0049)\n","   Epoch 09 | Train: 0.0050 | Val: 0.0048 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0048)\n","   Epoch 10 | Train: 0.0049 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0047)\n","   Epoch 11 | Train: 0.0048 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0047)\n","   Epoch 12 | Train: 0.0047 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0046)\n","   Epoch 13 | Train: 0.0046 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0045)\n","   Epoch 14 | Train: 0.0045 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0045)\n","   Epoch 15 | Train: 0.0044 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0044)\n","   Epoch 16 | Train: 0.0043 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0044)\n","   Epoch 17 | Train: 0.0043 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0044)\n","   Epoch 18 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0043)\n","   Epoch 19 | Train: 0.0041 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0043)\n","   Epoch 20 | Train: 0.0041 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0043)\n","   Epoch 21 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0042)\n","   Epoch 22 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0042)\n","   Epoch 23 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0042)\n","   Epoch 24 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0042)\n","   Epoch 25 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0042)\n","   Epoch 26 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 27 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 28 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 29 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 30 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 31 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 32 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 33 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 34 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 35 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 36 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 37 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 38 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 39 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 40 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 41 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 42 | Train: 0.0033 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 43 | Train: 0.0033 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 44 | Train: 0.0033 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 45 | Train: 0.0033 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 46 | Train: 0.0032 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 3 Model Saved! (0.0041)\n","   Epoch 47 | Train: 0.0032 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 48 | Train: 0.0032 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 49 | Train: 0.0032 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 50 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","\n","========================================\n","üîÑ FOLD 4/5\n","========================================\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   Epoch 01 | Train: 0.0375 | Val: 0.0058 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0058)\n","   Epoch 02 | Train: 0.0061 | Val: 0.0057 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0057)\n","   Epoch 03 | Train: 0.0059 | Val: 0.0056 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0056)\n","   Epoch 04 | Train: 0.0057 | Val: 0.0054 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0054)\n","   Epoch 05 | Train: 0.0055 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0052)\n","   Epoch 06 | Train: 0.0054 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0052)\n","   Epoch 07 | Train: 0.0052 | Val: 0.0050 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0050)\n","   Epoch 08 | Train: 0.0051 | Val: 0.0049 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0049)\n","   Epoch 09 | Train: 0.0049 | Val: 0.0048 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0048)\n","   Epoch 10 | Train: 0.0048 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0047)\n","   Epoch 11 | Train: 0.0047 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0047)\n","   Epoch 12 | Train: 0.0046 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0046)\n","   Epoch 13 | Train: 0.0045 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0046)\n","   Epoch 14 | Train: 0.0045 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0045)\n","   Epoch 15 | Train: 0.0044 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0045)\n","   Epoch 16 | Train: 0.0043 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0044)\n","   Epoch 17 | Train: 0.0042 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0044)\n","   Epoch 18 | Train: 0.0042 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0044)\n","   Epoch 19 | Train: 0.0041 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0044)\n","   Epoch 20 | Train: 0.0041 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0043)\n","   Epoch 21 | Train: 0.0040 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0043)\n","   Epoch 22 | Train: 0.0039 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0043)\n","   Epoch 23 | Train: 0.0039 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0043)\n","   Epoch 24 | Train: 0.0038 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0043)\n","   Epoch 25 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 26 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 27 | Train: 0.0037 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 28 | Train: 0.0037 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 29 | Train: 0.0037 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 30 | Train: 0.0036 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 31 | Train: 0.0036 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 32 | Train: 0.0035 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 33 | Train: 0.0035 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 34 | Train: 0.0035 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 35 | Train: 0.0035 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 36 | Train: 0.0034 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 37 | Train: 0.0034 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0042)\n","   Epoch 38 | Train: 0.0034 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 39 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0041)\n","   Epoch 40 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 4 Model Saved! (0.0041)\n","   Epoch 41 | Train: 0.0033 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 42 | Train: 0.0033 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 43 | Train: 0.0033 | Val: 0.0042 | LR: 2.0e-04\n","   Epoch 44 | Train: 0.0033 | Val: 0.0042 | LR: 1.0e-04\n","   Epoch 45 | Train: 0.0032 | Val: 0.0042 | LR: 1.0e-04\n","   Epoch 46 | Train: 0.0032 | Val: 0.0042 | LR: 1.0e-04\n","   Epoch 47 | Train: 0.0031 | Val: 0.0042 | LR: 1.0e-04\n","   Epoch 48 | Train: 0.0031 | Val: 0.0042 | LR: 5.0e-05\n","   Epoch 49 | Train: 0.0031 | Val: 0.0042 | LR: 5.0e-05\n","   Epoch 50 | Train: 0.0031 | Val: 0.0041 | LR: 5.0e-05\n","     ‚≠ê Best Fold 4 Model Saved! (0.0041)\n","\n","========================================\n","üîÑ FOLD 5/5\n","========================================\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   Epoch 01 | Train: 0.0375 | Val: 0.0058 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0058)\n","   Epoch 02 | Train: 0.0061 | Val: 0.0056 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0056)\n","   Epoch 03 | Train: 0.0059 | Val: 0.0055 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0055)\n","   Epoch 04 | Train: 0.0057 | Val: 0.0054 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0054)\n","   Epoch 05 | Train: 0.0055 | Val: 0.0052 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0052)\n","   Epoch 06 | Train: 0.0054 | Val: 0.0051 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0051)\n","   Epoch 07 | Train: 0.0052 | Val: 0.0050 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0050)\n","   Epoch 08 | Train: 0.0051 | Val: 0.0049 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0049)\n","   Epoch 09 | Train: 0.0049 | Val: 0.0048 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0048)\n","   Epoch 10 | Train: 0.0048 | Val: 0.0047 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0047)\n","   Epoch 11 | Train: 0.0047 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0046)\n","   Epoch 12 | Train: 0.0046 | Val: 0.0046 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0046)\n","   Epoch 13 | Train: 0.0045 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0045)\n","   Epoch 14 | Train: 0.0044 | Val: 0.0045 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0045)\n","   Epoch 15 | Train: 0.0044 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0044)\n","   Epoch 16 | Train: 0.0043 | Val: 0.0044 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0044)\n","   Epoch 17 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0043)\n","   Epoch 18 | Train: 0.0042 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0043)\n","   Epoch 19 | Train: 0.0041 | Val: 0.0043 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0043)\n","   Epoch 20 | Train: 0.0040 | Val: 0.0043 | LR: 2.0e-04\n","   Epoch 21 | Train: 0.0040 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0042)\n","   Epoch 22 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0042)\n","   Epoch 23 | Train: 0.0039 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0042)\n","   Epoch 24 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0042)\n","   Epoch 25 | Train: 0.0038 | Val: 0.0042 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0042)\n","   Epoch 26 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 27 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 28 | Train: 0.0037 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 29 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 30 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 31 | Train: 0.0036 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 32 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 33 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 34 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 35 | Train: 0.0035 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 36 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 37 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 38 | Train: 0.0034 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 39 | Train: 0.0033 | Val: 0.0041 | LR: 2.0e-04\n","   Epoch 40 | Train: 0.0033 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 41 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 42 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 43 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 44 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 45 | Train: 0.0032 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 46 | Train: 0.0031 | Val: 0.0041 | LR: 1.0e-04\n","     ‚≠ê Best Fold 5 Model Saved! (0.0041)\n","   Epoch 47 | Train: 0.0031 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 48 | Train: 0.0031 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 49 | Train: 0.0031 | Val: 0.0041 | LR: 1.0e-04\n","   Epoch 50 | Train: 0.0031 | Val: 0.0041 | LR: 5.0e-05\n","\n","‚úÖ K-FOLD TRAINING COMPLETED!\n"]}]},{"cell_type":"code","source":["print(f\"\\nüöÄ LOADING {CONFIG['N_FOLDS']} MODELS INTO VRAM...\")\n","models = []\n","\n","for fold in range(CONFIG['N_FOLDS']):\n","    model_path = f\"{CONFIG['SAVE_DIR']}/model_fold_{fold+1}.pth\"\n","    print(f\"   -> Loading: {os.path.basename(model_path)}\")\n","\n","    m = MultiModalNet(\n","        input_dims_list = INPUT_DIMS_LIST,\n","        encoder_layers  = CONFIG['ENCODER_LAYERS'],\n","        dropout         = CONFIG['DROPOUT_RATE'],\n","        num_classes     = len(top_terms)\n","    ).to(CONFIG['DEVICE'])\n","\n","    state_dict = torch.load(model_path, map_location=CONFIG['DEVICE'])\n","    m.load_state_dict(state_dict)\n","\n","    m.to(CONFIG['DEVICE'])\n","    m.eval()\n","    models.append(m)\n","\n","print(f\"‚úÖ All {len(models)} models loaded successfully!\")\n","\n","print(\"\\nüîÆ PREDICTING...\")\n","\n","test_paths = {k: v['test'] for k, v in CONFIG['EMBEDDINGS'].items()}\n","test_ids = np.load(CONFIG['TEST_ID_PATH'])\n","\n","# Test Dataset (Dual Memmap)\n","test_dataset = MultiSourceDataset(test_paths)\n","test_loader = DataLoader(test_dataset, batch_size=CONFIG['BATCH_SIZE']*2, shuffle=False, num_workers=2)\n","\n","submission_path = f\"{CONFIG['SAVE_DIR']}/submission.tsv\"\n","n_predictions = 0\n","\n","with open(submission_path, 'w') as f:\n","    current_idx = 0\n","    with torch.no_grad():\n","        for (X_b,) in tqdm(test_loader, desc=\"Inference\"):\n","            X_b = [x.to(CONFIG['DEVICE']) for x in X_b]\n","\n","            avg_probs = None\n","\n","            for model in models:\n","                logits = model(X_b)\n","                probs = torch.sigmoid(logits)\n","\n","                if avg_probs is None:\n","                    avg_probs = probs\n","                else:\n","                    avg_probs += probs\n","\n","            avg_probs /= len(models)\n","            probs_batch = avg_probs.cpu().numpy()\n","\n","            ids_batch = test_ids[current_idx : current_idx + len(probs_batch)]\n","            current_idx += len(probs_batch)\n","\n","            for i, pid in enumerate(ids_batch):\n","                probs = probs_batch[i]\n","\n","                # TOP-K C·ª®NG (Chi·∫øn thu·∫≠t 0.27 ƒëi·ªÉm)\n","                top_k = CONFIG['MAX_PREDS_PER_PROTEIN']\n","                ind = np.argpartition(probs, -top_k)[-top_k:]\n","                ind = ind[np.argsort(probs[ind])][::-1]\n","\n","                for idx in ind:\n","                    score = probs[idx]\n","                    if score > CONFIG['MIN_CONFIDENCE']:\n","                        f.write(f\"{pid}\\t{top_terms[idx]}\\t{score:.3f}\\n\")\n","                        n_predictions += 1\n","\n","            del probs_batch, X_b, avg_probs\n","\n","print(f\"\\n‚úÖ DONE! File: {submission_path}\")\n","print(f\"\\n‚úÖ DONE! Predictions: {n_predictions:,}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":813,"referenced_widgets":["4883ba290fc54b25926232ede5a1c93a","46ee4642daf44d17ab67ec95dd49c9eb","a0b2fb2ba01c4779922c0dd615c404d0","c55116d2846840279a45fa1b0bd7f8e8","125104fd769d4651a91e3bf32c84d0f8","8b3b2e80249d41ae9467f2b70bc85abe","d9ae3e2c33264d93b8da69237faccc92","d98b05e9a84d4621948533e1230b8cdf","38b98e0d3d354995900fb12bce96d6ac","b9212ff9c1034d9db947418df6b1cffe","4680b4b20c394bffacbb2aa5cb573b8e"]},"id":"nHEVTboSLxkq","executionInfo":{"status":"ok","timestamp":1765022089212,"user_tz":-420,"elapsed":64784,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"74c8d342-726e-4d1e-ed31-8c0bfb0fddff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üöÄ LOADING 5 MODELS INTO VRAM...\n","   -> Loading: model_fold_1.pth\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   -> Loading: model_fold_2.pth\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   -> Loading: model_fold_3.pth\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   -> Loading: model_fold_4.pth\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","   -> Loading: model_fold_5.pth\n","\n","üèóÔ∏è Building Advanced Architecture:\n","   ‚û§ Branch 1: Input 768 -> Output 512\n","   ‚û§ Branch 2: Input 1280 -> Output 512\n","   ‚û§ Branch 3: Input 1024 -> Output 512\n","   ‚û§ Fusion Dim: 1536\n","‚úÖ All 5 models loaded successfully!\n","\n","üîÆ PREDICTING...\n"]},{"output_type":"display_data","data":{"text/plain":["Inference:   0%|          | 0/877 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4883ba290fc54b25926232ede5a1c93a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ DONE! File: /content/drive/MyDrive/CAFA6_Results/prott5_esm2_ankh_k_fold_Run/submission.tsv\n","\n","‚úÖ DONE! Predictions: 4,415,813\n"]}]},{"cell_type":"code","source":["# Ch·∫°y l·ªánh n√†y trong m·ªôt cell m·ªõi\n","!kaggle competitions submit \\\n","    -c cafa-6-protein-function-prediction \\\n","    -f /content/drive/MyDrive/CAFA6_Results/prott5_esm2_ankh_k_fold_Run/submission.tsv \\\n","    -m \"esm2 ankh prot t5 5-fold\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfKYzKqwei36","executionInfo":{"status":"ok","timestamp":1765022145509,"user_tz":-420,"elapsed":4367,"user":{"displayName":"Hung Nguyen","userId":"06361922292825162630"}},"outputId":"9466535b-d916-4b70-9b32-bd01ef0df2e7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 101M/101M [00:02<00:00, 51.1MB/s] \n","Successfully submitted to CAFA 6 Protein Function Prediction"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3-a9eVb5FStU"},"execution_count":null,"outputs":[]}]}